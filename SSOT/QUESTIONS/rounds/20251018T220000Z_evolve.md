# Question Evolution Round: 20251018T220000Z

**Phase**: Q_AND_E  
**Timestamp**: 2025-10-18T22:00:00Z  
**Parent Round**: 20251018T215230Z  
**Status**: All components Red, 17 open questions, 7 open audits

## Context
- All 29 components remain Red
- Priority focus: CRITICAL components (C01, C05, C10, C11, C12, C13, C17, Infra)
- Previous round completed 3 P0 questions (feature parity, bid dedup, budget validation)
- Need to generate new high-leverage questions targeting remaining gaps

## Generated Questions (50 total)

```json
{
  "questions": [
    {
      "id": "Q_001",
      "area": "Data",
      "question": "How do we guarantee event_id deduplication across Kafka retries without Redis race conditions?",
      "why_it_matters": "A_005 requires dedup active but no implementation exists; duplicate events cause double-counting in MMM/MTA",
      "evidence_anchor": ["core/message_bus.py", "SSOT/COVERAGE/coverage.matrix.csv:C01"],
      "acceptance_signal": "Integration test shows 1000 duplicate event_ids result in exactly 1 processing per unique ID",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_002",
      "area": "Secrets",
      "question": "What is the exact Secret Manager integration pattern for PII salt rotation with 24h coexistence?",
      "why_it_matters": "Q_070 requires salt from Secret Manager; current code may hardcode salts violating GDPR rotation requirements",
      "evidence_anchor": ["core/security.py", "infrastructure/secrets/"],
      "acceptance_signal": "Test demonstrates salt rotation with old/new both valid for 24h, zero hash mismatches during transition",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_003",
      "area": "Data",
      "question": "How does schema drift detection trigger alerts within 5 minutes of detecting version mismatch?",
      "why_it_matters": "A_010 requires drift detector active; no observability for schema changes causing silent failures",
      "evidence_anchor": ["agents/schema_validator.py", "core/contracts.py"],
      "acceptance_signal": "Introduce v2 schema, alert fires in <5min with specific field differences enumerated",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_004",
      "area": "Data",
      "question": "What enforcement mechanism prevents features from being stored if freshness exceeds 6 hour SLA?",
      "why_it_matters": "A_012 requires freshness SLA=6h; stale features cause model degradation in MMM/MTA predictions",
      "evidence_anchor": ["agents/data_quality.py", "core/feature_store.py"],
      "acceptance_signal": "Test shows 6h01m old data rejected with DataQualityException, metrics emitted",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_005",
      "area": "Features",
      "question": "How do we validate MIN_RECORDS=100 enforcement before training MMM models to prevent statistical noise?",
      "why_it_matters": "Q_101 requires >=100 records; insufficient data causes unreliable Bayesian posteriors in PyMC models",
      "evidence_anchor": ["core/feature_store.py", "agents/mmm_agent.py"],
      "acceptance_signal": "Training call with 99 records raises ValueError with message 'Insufficient records: 99 < 100'",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_006",
      "area": "Strategy",
      "question": "What are the complete seasonality controls required for MMM to properly attribute holiday spend impact?",
      "why_it_matters": "A_009 identifies missing holiday controls; without them MMM attributes holiday lift to wrong channels",
      "evidence_anchor": ["agents/mmm_agent.py", "AGENT.md:MMM Formulas"],
      "acceptance_signal": "PyMC model includes holiday dummy variables with coefficient significance test p<0.05",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_007",
      "area": "Risk",
      "question": "How does MTA path aggregation enforce >=10 users per path to maintain privacy-safety?",
      "why_it_matters": "C05 Red; paths with <10 users expose individual behavior violating privacy-safe design principle",
      "evidence_anchor": ["agents/mta_agent.py", "AGENT.md:MTA Privacy"],
      "acceptance_signal": "Query shows all paths in conversion_path table have count >= 10, <10 paths suppressed",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_008",
      "area": "Governance",
      "question": "What LLM guardrail validates temperature <= 0.2 before any API call for determinism?",
      "why_it_matters": "Q_072 done but implementation unclear; temp>0.2 causes non-reproducible crisis briefs and creative variants",
      "evidence_anchor": ["agents/llm_guardrails.py", "config/model_registry.yaml"],
      "acceptance_signal": "Test shows temperature=0.5 rejected with ConfigurationError before API call",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_009",
      "area": "Governance",
      "question": "How do we enforce source_ids >= 2 in all LLM outputs to maintain RAG-only principle?",
      "why_it_matters": "Q_073 done but verification needed; 1 source allows LLM hallucination in crisis detection",
      "evidence_anchor": ["agents/llm_guardrails.py", "agents/crisis_detection.py"],
      "acceptance_signal": "LLM response with 1 source_id rejected with ValidationError, no storage occurs",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_010",
      "area": "Governance",
      "question": "What config mechanism prevents analyst and verifier LLMs from being the same model?",
      "why_it_matters": "Q_074 done; self-verification is impossible, separate models required for fact-checking",
      "evidence_anchor": ["config/model_registry.yaml", "agents/crisis_detection.py"],
      "acceptance_signal": "Config with analyst=verifier raises StartupError with message 'Models must differ'",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_011",
      "area": "Governance",
      "question": "How does crisis detection enforce >= 2 independent sources before marking risk_score > 0.5?",
      "why_it_matters": "Q_037/Q_088 require multi-source corroboration; single source causes false positive crisis alerts",
      "evidence_anchor": ["agents/crisis_detection.py", "AGENT.md:Crisis Brief Prompt"],
      "acceptance_signal": "Test with 1 source caps risk_score at 0.5, requires_human_review=true",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_012",
      "area": "Compliance",
      "question": "What validation blocks age < 18 targeting with 403 response to meet regulatory requirements?",
      "why_it_matters": "Q_009/Q_097 require age gate; targeting minors violates Japan/EU advertising regulations",
      "evidence_anchor": ["agents/compliance_agent.py", "infrastructure/api_gateway.py"],
      "acceptance_signal": "API call with age=17 returns 403 with message 'Age restriction: targeting minors prohibited'",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_013",
      "area": "Compliance",
      "question": "How does compliance agent reject creative copy lacking 'Promo/広告' label for Japan market?",
      "why_it_matters": "Q_021 requires promo label enforcement; unlabeled ads violate Japanese advertising law",
      "evidence_anchor": ["agents/compliance_agent.py", "AGENT.md:Compliance Prompts"],
      "acceptance_signal": "Creative text without 'Promo/広告' rejected with ComplianceError before activation",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_014",
      "area": "Execution",
      "question": "What idempotency mechanism prevents duplicate bid mutations when Kafka retries activation events?",
      "why_it_matters": "Q_004 done but need verification; duplicate mutations cause budget overruns and bid conflicts",
      "evidence_anchor": ["agents/activation_agent.py", "core/message_bus.py"],
      "acceptance_signal": "Send same mutation_id twice, only 1 API call made, second returns cached response",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_015",
      "area": "Execution",
      "question": "How does activation agent validate budget limits before pushing changes to ad platforms?",
      "why_it_matters": "Q_005/Q_082/Q_103 require pre-push validation; exceeding limits causes overspend and client escalations",
      "evidence_anchor": ["agents/activation_agent.py", "agents/budget_allocation_agent.py"],
      "acceptance_signal": "Allocation exceeding campaign limit returns 400 BadRequest, no external API call",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_016",
      "area": "Risk",
      "question": "What circuit breaker implementation halts all external API calls within 5 seconds on kill-switch?",
      "why_it_matters": "Q_013/Q_140 require emergency stop <5s; slow circuit breakers allow continued damage during incidents",
      "evidence_anchor": ["core/circuit_breaker.py", "infrastructure/api_gateway.py"],
      "acceptance_signal": "Trigger kill-switch, all in-flight requests complete or abort in <5s, metric circuit_breaker_triggered=1",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_017",
      "area": "Infra",
      "question": "How does rate limiter prevent LLM API quota exhaustion while allowing burst traffic?",
      "why_it_matters": "A_017 requires rate limiting; unlimited calls cause $10k+ bills and quota lockouts",
      "evidence_anchor": ["core/rate_limiter.py", "config/model_registry.yaml"],
      "acceptance_signal": "101st request in 1 hour window returns 429 RateLimitExceeded, metrics show tokens/hour tracked",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_018",
      "area": "Observability",
      "question": "What OpenTelemetry instrumentation enables end-to-end tracing from API gateway to database?",
      "why_it_matters": "Q_006/Q_078 require distributed tracing; cannot debug latency spikes without span context propagation",
      "evidence_anchor": ["core/tracing.py", "infrastructure/api_gateway.py"],
      "acceptance_signal": "Jaeger UI shows complete trace with spans for gateway→service→DB, total latency <5s",
      "urgency": "P0",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_019",
      "area": "RBAC",
      "question": "How does JWT validation enforce role-based access with 403 for insufficient permissions?",
      "why_it_matters": "Q_018/Q_075 require RBAC; missing auth allows unauthorized budget changes and PII access",
      "evidence_anchor": ["infrastructure/api_gateway.py", "core/rbac.py"],
      "acceptance_signal": "Request with role='viewer' to /admin/budget returns 403 with message 'Insufficient permissions'",
      "urgency": "P0",
      "owner_hint": "RBAC"
    },
    {
      "id": "Q_020",
      "area": "RBAC",
      "question": "What RBAC policy restricts pii_mapping table access to only users with 'pii_admin' role?",
      "why_it_matters": "Q_038 requires PII RBAC restriction; over-permissive access violates least-privilege principle",
      "evidence_anchor": ["core/rbac.py", "infrastructure/database.py"],
      "acceptance_signal": "Query pii_mapping with role='analyst' returns PermissionDenied, only pii_admin succeeds",
      "urgency": "P0",
      "owner_hint": "RBAC"
    },
    {
      "id": "Q_021",
      "area": "Secrets",
      "question": "How do we audit all code paths to ensure zero secrets in environment variables?",
      "why_it_matters": "Q_007/Q_090 require no env var secrets; logged env vars expose API keys and database passwords",
      "evidence_anchor": ["core/security.py", ".env.template"],
      "acceptance_signal": "CI regex scan fails on patterns like 'API_KEY=sk-' in .env, exit code 1",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_022",
      "area": "Secrets",
      "question": "What HMAC-SHA256 validation prevents webhook spoofing with 401 on signature mismatch?",
      "why_it_matters": "Q_010/Q_098 require HMAC validation; missing auth allows attackers to inject fake conversion events",
      "evidence_anchor": ["agents/webhook_receiver.py", "core/security.py"],
      "acceptance_signal": "Webhook with invalid HMAC returns 401 Unauthorized, valid HMAC processes event",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_023",
      "area": "CI/CD",
      "question": "What deployment gate blocks production rollout if pytest fails in CI pipeline?",
      "why_it_matters": "Q_008/Q_092 require test gate; broken code deploys cause production incidents",
      "evidence_anchor": [".github/workflows/deploy.yaml", "tests/"],
      "acceptance_signal": "Introduce failing test, deployment workflow exits with code 1, no container push",
      "urgency": "P0",
      "owner_hint": "CI/CD"
    },
    {
      "id": "Q_024",
      "area": "Monitoring",
      "question": "How does PagerDuty integration guarantee P0 error alerts reach on-call within 2 minutes?",
      "why_it_matters": "Q_011/Q_100 require <2min SLA; slow alerts increase MTTR from minutes to hours",
      "evidence_anchor": ["infrastructure/alertmanager.yaml", "config/pagerduty.yaml"],
      "acceptance_signal": "Trigger P0 alert, PagerDuty webhook fires in <120s, on-call receives notification",
      "urgency": "P0",
      "owner_hint": "Monitoring"
    },
    {
      "id": "Q_025",
      "area": "Data",
      "question": "What schema versioning strategy allows v1 clients to deserialize v2 messages without breaking?",
      "why_it_matters": "Q_071 requires backward compat; version mismatches cause event processing failures during gradual rollouts",
      "evidence_anchor": ["core/contracts.py", "core/message_bus.py"],
      "acceptance_signal": "v2 producer sends message, v1 consumer processes it successfully ignoring new fields",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_026",
      "area": "Strategy",
      "question": "How do MMM adstock curves validate half-life parameters against empirical decay patterns?",
      "why_it_matters": "A_009 missing validation; incorrect adstock causes misattribution of lagged channel effects",
      "evidence_anchor": ["agents/mmm_agent.py", "AGENT.md:Adstock Formula"],
      "acceptance_signal": "Posterior check shows adstock_alpha 95% CI within [0.2, 0.8], empirically validated",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_027",
      "area": "Strategy",
      "question": "What Hill function saturation validation prevents unrealistic ROI curve predictions?",
      "why_it_matters": "MMM saturation_point unbounded causes optimizer to recommend infinite spend",
      "evidence_anchor": ["agents/mmm_agent.py", "AGENT.md:Saturation Formula"],
      "acceptance_signal": "Saturation_beta constrained to [0.5, 2.0], theta validated against historical max spend",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_028",
      "area": "Strategy",
      "question": "How does MTA Markov model handle zero-transition states without causing division errors?",
      "why_it_matters": "Channels with zero conversions cause NaN in probability calculations",
      "evidence_anchor": ["agents/mta_agent.py", "AGENT.md:Markov Attribution"],
      "acceptance_signal": "Test path with zero START→CHANNEL transition, smoothing adds epsilon=1e-6 to avoid division by zero",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_029",
      "area": "Planner",
      "question": "What budget optimization constraints prevent allocations below channel-specific minimum spend?",
      "why_it_matters": "Optimizer recommends $0 spend to unprofitable channels causing loss of brand presence",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "AGENT.md:Budget Optimization"],
      "acceptance_signal": "Optimization with meta min=$10k, solution respects constraint, scipy exit status 0",
      "urgency": "P1",
      "owner_hint": "Planner"
    },
    {
      "id": "Q_030",
      "area": "Planner",
      "question": "How does playbook orchestrator enforce 24-hour approval timeout with auto-escalation?",
      "why_it_matters": "A_011 requires timeout; stuck approvals block time-sensitive budget reallocations",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "agents/approval_agent.py"],
      "acceptance_signal": "Approval pending 24h01m triggers auto-escalate to CMO, Slack notification sent",
      "urgency": "P1",
      "owner_hint": "Planner"
    },
    {
      "id": "Q_031",
      "area": "Critic",
      "question": "What creative fatigue detection algorithm identifies declining CTR with statistical significance?",
      "why_it_matters": "False positive fatigue causes premature creative pausing, reducing overall performance",
      "evidence_anchor": ["agents/creative_intelligence_agent.py", "AGENT.md:Fatigue Detection"],
      "acceptance_signal": "Linear regression slope test p<0.05 triggers fatigue=true, p>=0.05 keeps status=active",
      "urgency": "P1",
      "owner_hint": "Critic"
    },
    {
      "id": "Q_032",
      "area": "Critic",
      "question": "How does asset fingerprinting prevent duplicate creatives from being uploaded?",
      "why_it_matters": "A_018 missing fingerprinting; duplicate assets waste budget and confuse performance analysis",
      "evidence_anchor": ["agents/creative_intelligence_agent.py", "core/contracts.py"],
      "acceptance_signal": "Upload same image twice, second attempt returns DuplicateAssetError with existing asset_id",
      "urgency": "P1",
      "owner_hint": "Critic"
    },
    {
      "id": "Q_033",
      "area": "Rules",
      "question": "What dry-run mode allows playbooks to simulate actions without external API calls?",
      "why_it_matters": "Testing playbooks against production data risks accidental budget changes",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "agents/activation_agent.py"],
      "acceptance_signal": "Playbook with dry_run=true logs intended actions, makes zero external calls",
      "urgency": "P1",
      "owner_hint": "Rules"
    },
    {
      "id": "Q_034",
      "area": "Risk",
      "question": "How do audience expansion tests implement early stopping on losing variants to minimize waste?",
      "why_it_matters": "Full-duration tests on failing variants waste budget that could go to winners",
      "evidence_anchor": ["agents/audience_expansion_agent.py", "agents/ab_test_agent.py"],
      "acceptance_signal": "Bayesian test detects loser p<0.05 after day 3, auto-stops variant, reallocates budget",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_035",
      "area": "Risk",
      "question": "What Bayesian A/B test computes probability-of-being-best for creative variants?",
      "why_it_matters": "Frequentist tests require fixed sample size; Bayesian allows continuous monitoring",
      "evidence_anchor": ["agents/ab_test_agent.py", "AGENT.md:Bayesian A/B Test"],
      "acceptance_signal": "Test returns P(variant_best) > 0.95, declares winner, scales budget to 70%",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_036",
      "area": "Execution",
      "question": "How does bid optimization predict optimal bids using time-of-day and day-of-week features?",
      "why_it_matters": "Static bids miss high-conversion time windows causing inefficient spend",
      "evidence_anchor": ["agents/bid_guidance_agent.py", "core/feature_store.py"],
      "acceptance_signal": "Model includes hour_of_day and day_of_week features, prediction MAPE <15%",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_037",
      "area": "Execution",
      "question": "What negative keyword discovery clusters wasted spend search terms by semantic similarity?",
      "why_it_matters": "Manual keyword review misses patterns; automated clustering finds hidden waste",
      "evidence_anchor": ["agents/search_term_agent.py", "agents/nlp_agent.py"],
      "acceptance_signal": "Cluster 50 low-CVR terms, generate phrase match negatives, spend reduces by >10%",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_038",
      "area": "Latency",
      "question": "What caching strategy reduces LLM API latency by reusing identical prompt hashes?",
      "why_it_matters": "Repeated prompts cause unnecessary API cost and latency; cache saves 80%+ of calls",
      "evidence_anchor": ["core/finops.py", "agents/llm_guardrails.py"],
      "acceptance_signal": "Same prompt called twice, first hits API, second returns cached in <50ms",
      "urgency": "P1",
      "owner_hint": "Latency"
    },
    {
      "id": "Q_039",
      "area": "Latency",
      "question": "How does batch LLM processing reduce total latency using asyncio.gather concurrency?",
      "why_it_matters": "Sequential calls to LLM add N*latency; concurrent calls reduce to max(latency)",
      "evidence_anchor": ["core/finops.py", "agents/creative_intelligence_agent.py"],
      "acceptance_signal": "Process 10 prompts: sequential=30s, concurrent=4s using asyncio.gather",
      "urgency": "P1",
      "owner_hint": "Latency"
    },
    {
      "id": "Q_040",
      "area": "RAG",
      "question": "What embedding model provides multilingual support for ja/vi/en RAG retrieval?",
      "why_it_matters": "English-only embeddings fail to retrieve Japanese/Vietnamese source documents",
      "evidence_anchor": ["config/model_registry.yaml", "agents/llm_council.py"],
      "acceptance_signal": "Query in Japanese retrieves relevant Japanese docs with cosine similarity >0.7",
      "urgency": "P1",
      "owner_hint": "RAG"
    },
    {
      "id": "Q_041",
      "area": "RAG",
      "question": "How does reranker improve retrieval precision after initial embedding search?",
      "why_it_matters": "Embedding search returns false positives; reranking filters to top-k most relevant",
      "evidence_anchor": ["agents/llm_council.py", "config/model_registry.yaml"],
      "acceptance_signal": "Reranker reduces top-5 results to top-2 with relevance score >0.8",
      "urgency": "P1",
      "owner_hint": "RAG"
    },
    {
      "id": "Q_042",
      "area": "Governance",
      "question": "What toxicity detector prevents harmful content in LLM-generated creative variants?",
      "why_it_matters": "Unfiltered LLM outputs may contain offensive language causing brand damage",
      "evidence_anchor": ["agents/llm_guardrails.py", "agents/creative_intelligence_agent.py"],
      "acceptance_signal": "Text with toxicity_score >0.8 rejected with ValidationError, variant discarded",
      "urgency": "P1",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_043",
      "area": "Governance",
      "question": "How does PII detector block outputs containing email/phone in LLM responses?",
      "why_it_matters": "LLM may leak PII from training data violating privacy principles",
      "evidence_anchor": ["agents/llm_guardrails.py", "core/security.py"],
      "acceptance_signal": "Response with email pattern rejected with PIIDetectedError, no storage occurs",
      "urgency": "P1",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_044",
      "area": "Compliance",
      "question": "What audit log ensures immutability and 7-year retention for regulatory compliance?",
      "why_it_matters": "A_015 requires immutable logs; mutable logs allow tampering, violating GDPR/SOX requirements",
      "evidence_anchor": ["core/audit.py", "infrastructure/database.py"],
      "acceptance_signal": "Attempt UPDATE on audit_log returns ImmutableRecordError, retention policy set to 2555d",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_045",
      "area": "Compliance",
      "question": "How does multi-currency revenue tracking maintain historical FX rates for accurate reporting?",
      "why_it_matters": "A_016 requires historical FX; using current rates causes inaccurate ROI calculations",
      "evidence_anchor": ["core/contracts.py", "agents/analytics_agent.py"],
      "acceptance_signal": "Order in EUR on 2025-01-01 uses FX rate from that date, not current rate",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_046",
      "area": "Observability",
      "question": "What metrics track LLM token usage and cost per model/task for budget monitoring?",
      "why_it_matters": "Untracked LLM costs cause budget overruns; need per-model visibility",
      "evidence_anchor": ["core/finops.py", "infrastructure/prometheus.yaml"],
      "acceptance_signal": "Prometheus query llm_cost_usd shows breakdown by model (claude, gpt) and task",
      "urgency": "P1",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_047",
      "area": "Observability",
      "question": "How do model drift detectors trigger retraining when MMM MAPE exceeds 15% threshold?",
      "why_it_matters": "Drifted models cause poor budget allocation; automated detection reduces manual monitoring",
      "evidence_anchor": ["agents/monitoring_agent.py", "agents/mmm_agent.py"],
      "acceptance_signal": "MAPE reaches 16%, alert fires, retraining workflow triggered automatically",
      "urgency": "P1",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_048",
      "area": "Infra",
      "question": "What PostgreSQL connection pooling prevents exhaustion under high request volume?",
      "why_it_matters": "Unlimited connections cause database OOM and query timeouts during traffic spikes",
      "evidence_anchor": ["infrastructure/database.py", "core/feature_store.py"],
      "acceptance_signal": "Pool max_connections=200, 201st request waits or returns ResourceExhaustedError",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_049",
      "area": "Infra",
      "question": "How does Redis cluster failover maintain feature store availability during node failures?",
      "why_it_matters": "Single Redis node failure causes complete feature store outage; HA required",
      "evidence_anchor": ["infrastructure/redis.yaml", "core/feature_store.py"],
      "acceptance_signal": "Kill primary node, failover to replica in <30s, queries continue successfully",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_050",
      "area": "Other",
      "question": "What runbook documents step-by-step incident response for P0 production issues?",
      "why_it_matters": "Missing runbooks cause confusion during incidents, increasing MTTR from minutes to hours",
      "evidence_anchor": ["docs/runbooks/", "SSOT/COVERAGE/coverage.matrix.csv"],
      "acceptance_signal": "Runbook exists for each CRITICAL component with clear steps, contact info, rollback procedures",
      "urgency": "P2",
      "owner_hint": "Observability"
    }
  ]
}
```

## Reconciliation Notes
- Total questions: 50 (IDs Q_001 through Q_050)
- Priority distribution: 25 P0, 24 P1, 1 P2
- All questions tied to current Red components
- Focus on CRITICAL components: 18 questions
- Coverage of all required areas: Data, Features, Strategy, Risk, Execution, Governance, RBAC, Secrets, Observability, CI/CD, Compliance, Infra
- All questions have clear acceptance signals and evidence anchors
- Questions are capsule-ready with concise titles and why statements

## Next Actions
1. Merge these 50 questions into INTENT_CAPSULE.md under open_questions
2. Deduplicate against existing questions
3. Maintain capsule size <= 1.5KB
4. Update question pointers
5. Proceed to AUDIT phase (call #2)
