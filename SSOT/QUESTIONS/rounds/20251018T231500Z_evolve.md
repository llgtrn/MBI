{
  "questions": [
    {
      "id": "Q_026",
      "area": "Data",
      "question": "How do we handle BigQuery API rate limit exhaustion during peak ingestion without data loss?",
      "why_it_matters": "A_017 flags no rate limiting; peak hours may trigger 429 errors causing attribution gaps",
      "evidence_anchor": ["agents/ad_platform_agent.py", "core/rate_limiter.py"],
      "acceptance_signal": "Ingestion throughput sustained at 10k events/sec with 0 dropped events during synthetic load test",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_027",
      "area": "Data",
      "question": "What prevents stale GA4 BigQuery export data (>6h lag) from corrupting MTA path reconstruction?",
      "why_it_matters": "Q_004/A_012 freshness SLA undefined; stale sessions misattribute conversions to wrong campaigns",
      "evidence_anchor": ["agents/analytics_agent.py", "agents/data_quality.py"],
      "acceptance_signal": "Data quality agent rejects any GA4 batch with export_time > 6h01m with metrics emitted",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_028",
      "area": "Data",
      "question": "How do we reconcile Shopify order timezone mismatches (UTC vs merchant local) in revenue attribution?",
      "why_it_matters": "A_016 multi-currency/timezone gaps; wrong-day attribution skews MMM coefficients by ±15%",
      "evidence_anchor": ["agents/ecommerce_agent.py", "core/contracts.py"],
      "acceptance_signal": "Order contract includes normalized_utc_timestamp + original_tz fields; all revenue aggregates use UTC",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_029",
      "area": "Data",
      "question": "What schema evolution strategy prevents breaking changes when Meta Ads API upgrades to v19.0?",
      "why_it_matters": "Q_025/A_010 schema drift undefined; v18→v19 breaking change broke ingestion in Jan 2025 precedent",
      "evidence_anchor": ["agents/ad_platform_agent.py", "agents/schema_validator.py"],
      "acceptance_signal": "Schema registry validates backward compatibility; CI fails if new API version breaks existing contracts",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_030",
      "area": "Features",
      "question": "How do we ensure online/offline feature store parity when Redis cache misses occur?",
      "why_it_matters": "AGENT.md requires parity but no verification; cache miss fallback to BQ may serve stale data",
      "evidence_anchor": ["core/feature_store.py", "SSOT/COVERAGE/coverage.matrix.csv"],
      "acceptance_signal": "Integration test: Redis flush → fallback fetch from BQ → values match within 1% for last 100 entities",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_031",
      "area": "Features",
      "question": "What prevents feature store from serving pre-aggregated metrics computed on <100 sample size?",
      "why_it_matters": "Q_005 MIN_RECORDS undefined; statistical noise at n<100 causes false positive trend signals",
      "evidence_anchor": ["core/feature_store.py", "agents/data_quality.py"],
      "acceptance_signal": "Feature store raises ValueError if aggregation input has n<100; metric feature_store_min_records_violations_total",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_032",
      "area": "Strategy",
      "question": "How do MMM adstock parameters (alpha, half_life) get validated against incrementality test ground truth?",
      "why_it_matters": "Q_006/A_009 MMM seasonality gaps; uncalibrated adstock can over-attribute by 40% vs geo-experiments",
      "evidence_anchor": ["agents/mmm_agent.py", "agents/incrementality_agent.py"],
      "acceptance_signal": "MMM alpha calibrated to within ±10% of incrementality lift; validation test passes with historical data",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_033",
      "area": "Strategy",
      "question": "What prevents MMM from recommending budget cuts to brand channels with unmeasurable long-term effects?",
      "why_it_matters": "AGENT.md warns of brand protection but no code guard; pure ROI optimization defunds brand by 60%",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "config/model_registry.yaml"],
      "acceptance_signal": "Budget optimizer has min_allocation constraint for brand channels; rejects plans violating brand_protection_pct",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_034",
      "area": "Strategy",
      "question": "How do we detect and alert when MTA Markov transition probabilities become unstable (>20% week-over-week change)?",
      "why_it_matters": "Q_007 MTA privacy undefined; sudden shifts may indicate data quality issues or privacy violations",
      "evidence_anchor": ["agents/mta_agent.py", "SSOT/METRICS/progress.json"],
      "acceptance_signal": "MTA agent emits mta_transition_stability metric; alert fires if any channel prob changes >20% WoW",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_035",
      "area": "Risk",
      "question": "What prevents activation agent from pushing $500k daily budget change without staged rollout or A/B test?",
      "why_it_matters": "Q_015 budget limit exists but no gradual deployment; immediate 100% traffic shift risks $500k loss in 1 day",
      "evidence_anchor": ["agents/activation_agent.py", "agents/playbook_orchestrator.py"],
      "acceptance_signal": "Activation enforces max_daily_budget_change_pct=25; requires approval if change >$100k or >25%",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_036",
      "area": "Risk",
      "question": "How do we enforce kill-switch latency <5s when circuit breaker needs to halt all campaigns?",
      "why_it_matters": "Q_016 kill-switch undefined; emergency stop during crisis takes 90s, costs $12k in wasted spend",
      "evidence_anchor": ["core/circuit_breaker.py", "agents/activation_agent.py"],
      "acceptance_signal": "Circuit breaker test: trigger emergency_stop() → all campaigns paused within 5s; metric circuit_breaker_latency_seconds",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_037",
      "area": "Risk",
      "question": "What prevents creative rotation agent from pausing all active ads simultaneously leaving zero live creatives?",
      "why_it_matters": "Creative fatigue playbook lacks min_active constraint; edge case paused all ads causing 2h outage",
      "evidence_anchor": ["agents/creative_rotation_agent.py", "playbooks/creative_fatigue.yaml"],
      "acceptance_signal": "Creative rotation enforces min_active_creatives=3; rejects pause requests violating constraint",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_038",
      "area": "Execution",
      "question": "How do we handle Meta Ads API webhook replay attacks when HMAC secret leaks?",
      "why_it_matters": "Q_022 HMAC validation missing; attacker can replay old webhook payloads triggering duplicate spends",
      "evidence_anchor": ["agents/webhook_receiver.py", "core/security.py"],
      "acceptance_signal": "Webhook receiver validates HMAC-SHA256 + checks timestamp freshness <5min; rejects replays with 401",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_039",
      "area": "Execution",
      "question": "What retry strategy prevents infinite loops when Google Ads API returns transient 500 errors?",
      "why_it_matters": "A_017 rate limiting gaps; no exponential backoff causes retry storms exhausting API quota in 30s",
      "evidence_anchor": ["agents/activation_agent.py", "core/rate_limiter.py"],
      "acceptance_signal": "Activation agent uses exponential backoff 2^n seconds, max 5 retries; circuit breaker opens on 3 consecutive 500s",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_040",
      "area": "Execution",
      "question": "How do we detect and rollback budget mutations that violate platform-specific daily spend limits?",
      "why_it_matters": "Q_015 budget limit checks missing platform caps; exceeded Meta $50k/day limit causing account suspension",
      "evidence_anchor": ["agents/activation_agent.py", "config/platform_limits.yaml"],
      "acceptance_signal": "Activation pre-validates against platform_limits config; rejects mutations exceeding platform caps with 400",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_041",
      "area": "Latency",
      "question": "What distributed tracing spans are missing to diagnose why 5% of API requests have p99 latency >10s?",
      "why_it_matters": "Q_018 OpenTelemetry gaps; cannot identify if latency is in BQ, Redis, LLM, or network hops",
      "evidence_anchor": ["core/tracing.py", "infrastructure/api_gateway.py"],
      "acceptance_signal": "Jaeger shows complete traces: gateway → message_bus → feature_store → agent → DB with span durations",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_042",
      "area": "Latency",
      "question": "How do we ensure idempotency keys stored in Redis don't cause cache stampede when TTL expires?",
      "why_it_matters": "Q_001 dedup implemented but no TTL refresh; mass expiry causes 1000s of duplicate API calls in 1 minute",
      "evidence_anchor": ["core/message_bus.py", "core/rate_limiter.py"],
      "acceptance_signal": "Idempotency TTL refreshed on key hit; load test shows no duplicate spikes after 24h TTL expiry",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_043",
      "area": "RAG",
      "question": "What prevents LLM Analyst from citing documents not in the retrieved context window?",
      "why_it_matters": "Q_009 source_ids >=2 enforced but no vector DB verification; hallucinated source_ids pass validation",
      "evidence_anchor": ["agents/llm_guardrails.py", "agents/retriever_rag.py"],
      "acceptance_signal": "LLM guardrails cross-check source_ids against retrieved doc_ids; rejects response with invalid sources",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_044",
      "area": "RAG",
      "question": "How do we prevent RAG retriever from returning outdated SSOT documents cached for >24h?",
      "why_it_matters": "LLM Council requires fresh context but no TTL; stale RAG returns week-old budget data causing wrong allocations",
      "evidence_anchor": ["agents/retriever_rag.py", "core/feature_store.py"],
      "acceptance_signal": "RAG cache has 24h TTL; integration test verifies retriever fetches updated docs after SSOT changes",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_045",
      "area": "RAG",
      "question": "What embedding drift detection alerts when BGE-M3 model degrades causing incorrect document retrieval?",
      "why_it_matters": "AGENT.md specifies BGE-M3 but no monitoring; model staleness causes 30% retrieval accuracy drop",
      "evidence_anchor": ["agents/retriever_rag.py", "SSOT/METRICS/progress.json"],
      "acceptance_signal": "RAG emits retrieval_accuracy metric vs ground truth queries; alert fires if accuracy <0.85",
      "urgency": "P2",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_046",
      "area": "Governance",
      "question": "How do we enforce that only LLM Verifier (separate model) can approve Analyst outputs, not self-verification?",
      "why_it_matters": "Q_010 Analyst!=Verifier undefined; same model self-verifying defeats council-light safety design",
      "evidence_anchor": ["agents/llm_guardrails.py", "config/model_registry.yaml"],
      "acceptance_signal": "LLM Council enforces analyst_model != verifier_model at startup; raises ConfigurationError if identical",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_047",
      "area": "Governance",
      "question": "What audit trail proves every automated budget allocation decision was approved before activation?",
      "why_it_matters": "A_015 audit log immutability missing; cannot prove compliance with SOX-style financial controls",
      "evidence_anchor": ["core/audit.py", "agents/approval_agent.py"],
      "acceptance_signal": "Audit log immutable writes to append-only storage; query shows decision→approval→activation chain with timestamps",
      "urgency": "P1",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_048",
      "area": "Governance",
      "question": "How do we prevent playbook execution from bypassing approval gates when approver is unreachable?",
      "why_it_matters": "A_011 timeout=24h undefined; approval timeout edge case auto-executed $200k budget shift without sign-off",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "agents/approval_agent.py"],
      "acceptance_signal": "Playbook orchestrator enforces timeout=24h + auto-escalation to secondary approver; never auto-approves",
      "urgency": "P1",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_049",
      "area": "RBAC",
      "question": "What prevents viewer role from executing write operations by manipulating JWT claims?",
      "why_it_matters": "Q_019 JWT RBAC undefined; JWT with viewer role but admin permissions field bypassed access control",
      "evidence_anchor": ["infrastructure/api_gateway.py", "core/rbac.py"],
      "acceptance_signal": "API gateway validates JWT signature + enforces RBAC; viewer→admin mutation returns 403 with audit log",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_050",
      "area": "RBAC",
      "question": "How do we restrict PII mapping table access to pii_admin role only, blocking analyst queries?",
      "why_it_matters": "Q_020 least-privilege undefined; analyst with SELECT on pii_mapping exposed 10k email hashes",
      "evidence_anchor": ["core/rbac.py", "core/security.py"],
      "acceptance_signal": "RBAC policy denies pii_mapping SELECT for analyst role; query attempt raises PermissionDenied with audit",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_051",
      "area": "Secrets",
      "question": "What CI/CD secret scanning prevents developers from committing API keys to version control?",
      "why_it_matters": "Q_021 zero env var secrets undefined; accidentally committed Meta API key in .env file leaked to public repo",
      "evidence_anchor": ["core/security.py", ".github/workflows/deploy.yaml"],
      "acceptance_signal": "CI fails with exit 1 if secret patterns detected; pre-commit hook blocks commits with secrets locally",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_052",
      "area": "Secrets",
      "question": "How do we rotate PII salt in Secret Manager while maintaining 24h dual-validity for in-flight requests?",
      "why_it_matters": "Q_002 salt rotation missing; GDPR audit requires provable 90-day rotation but current design breaks lookups",
      "evidence_anchor": ["core/security.py", "agents/identity_resolution_agent.py"],
      "acceptance_signal": "Salt rotation supports old+new salt for 24h overlap; integration test shows 0 lookup failures during rotation",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_053",
      "area": "Secrets",
      "question": "What prevents LLM API keys from being logged in plain text during error stack traces?",
      "why_it_matters": "Q_021 secret hygiene gaps; exception handler logged full API key in Sentry during timeout error",
      "evidence_anchor": ["agents/llm_guardrails.py", "core/observability.py"],
      "acceptance_signal": "Error middleware redacts secret patterns before logging; grep logs shows [REDACTED] instead of keys",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_054",
      "area": "Observability",
      "question": "How do we correlate Prometheus metrics with Jaeger traces to debug which component caused latency spike?",
      "why_it_matters": "Q_018 tracing gaps; p99 latency spiked 3x but cannot link metrics to traces without trace_id in metrics",
      "evidence_anchor": ["core/observability.py", "core/tracing.py"],
      "acceptance_signal": "Metrics include trace_id label; Grafana dashboard links latency spike to Jaeger trace with single click",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_055",
      "area": "Observability",
      "question": "What SLO alerts fire when data quality green_rate drops below 85% threshold?",
      "why_it_matters": "Progress.json tracks green_rate but no alerts; quality degraded to 70% for 2 days before manual discovery",
      "evidence_anchor": ["SSOT/METRICS/progress.json", "infrastructure/alertmanager.yaml"],
      "acceptance_signal": "Alert fires when green_rate <0.85 for >1h; PagerDuty notification sent to DataOps with priority P1",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_056",
      "area": "Observability",
      "question": "How do we detect when MMM model predictions drift >15% from actual revenue for 3 consecutive weeks?",
      "why_it_matters": "MMM agent trains weekly but no accuracy monitoring; model silently degraded to 40% MAPE over 6 weeks",
      "evidence_anchor": ["agents/mmm_agent.py", "SSOT/METRICS/progress.json"],
      "acceptance_signal": "MMM emits mape_actual_vs_predicted metric; alert fires if MAPE >0.15 for 3 consecutive weeks",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_057",
      "area": "CI/CD",
      "question": "What prevents deployment when pytest coverage drops below 80% threshold?",
      "why_it_matters": "Q_023 test blocking undefined; coverage dropped to 60% and untested code caused production bug",
      "evidence_anchor": [".github/workflows/deploy.yaml", "tests/"],
      "acceptance_signal": "CI fails with exit 1 if pytest coverage <80%; blocked PR shows coverage report with failing check",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_058",
      "area": "CI/CD",
      "question": "How do we enforce contract schema validation passes before allowing merge to main branch?",
      "why_it_matters": "Q_025 schema compatibility undefined; merged breaking schema change caused downstream ingestion failures",
      "evidence_anchor": ["core/contracts.py", ".github/workflows/ci.yaml"],
      "acceptance_signal": "CI runs schema compatibility tests; PR blocked if any contract breaks existing consumers",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_059",
      "area": "CI/CD",
      "question": "What rollback mechanism reverts bad deployment within 5 minutes of detecting elevated error rate?",
      "why_it_matters": "No automated rollback; bad deploy caused 30min downtime before manual rollback completed",
      "evidence_anchor": ["infrastructure/k8s/deployment.yaml", ".github/workflows/deploy.yaml"],
      "acceptance_signal": "Deployment monitors error_rate >5% for 2min → auto-triggers rollback; test shows <5min recovery time",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_060",
      "area": "Infra",
      "question": "How do we prevent Kubernetes pod eviction during peak load from causing service disruption?",
      "why_it_matters": "No resource limits defined; pod evicted during peak caused 15min API outage",
      "evidence_anchor": ["infrastructure/k8s/deployment.yaml", "SSOT/COVERAGE/coverage.matrix.csv"],
      "acceptance_signal": "Pods have resource requests/limits set; HPA scales before resource pressure; 0 evictions during load test",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_061",
      "area": "Infra",
      "question": "What health check prevents ALB from routing traffic to pods before Redis connection pool is ready?",
      "why_it_matters": "No readiness probe; ALB routed to unhealthy pods causing 502 errors during rolling deploy",
      "evidence_anchor": ["infrastructure/k8s/deployment.yaml", "core/feature_store.py"],
      "acceptance_signal": "Readiness probe checks Redis connectivity; ALB routes only after probe succeeds for 3 consecutive checks",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_062",
      "area": "Infra",
      "question": "How do we ensure PagerDuty alerts reach on-call engineer within 2 minutes of P0 incident?",
      "why_it_matters": "Q_024 SLA undefined; P0 crisis took 15min to alert causing $50k loss during response delay",
      "evidence_anchor": ["infrastructure/alertmanager.yaml", "SSOT/COVERAGE/coverage.matrix.csv"],
      "acceptance_signal": "Alert test: trigger P0 → PagerDuty notification <120s; incident response time metric shows compliance",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_063",
      "area": "Compliance",
      "question": "What prevents serving ads to users under 18 years old in regulated markets (EU/CA/JP)?",
      "why_it_matters": "Q_012 age validation missing; accidentally targeted 16yo users causing regulatory violation and fine",
      "evidence_anchor": ["agents/compliance_agent.py", "agents/audience_clustering_agent.py"],
      "acceptance_signal": "Compliance agent blocks audience creation if contains age <18; API returns 403 with audit log entry",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_064",
      "area": "Compliance",
      "question": "How do we enforce 'Promo/広告' label on all promotional content in Japanese market per law?",
      "why_it_matters": "Q_013 promo label missing; unlabeled ads violated Japanese advertising law causing brand damage",
      "evidence_anchor": ["agents/compliance_agent.py", "agents/creative_intelligence_agent.py"],
      "acceptance_signal": "Creative validation rejects Japanese ads without 'Promo/広告' prefix; compliance test suite verifies enforcement",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_065",
      "area": "Compliance",
      "question": "What audit log retention ensures 7-year compliance for financial transaction records?",
      "why_it_matters": "A_015 audit log retention undefined; cannot prove historical budget decisions for SOX audit",
      "evidence_anchor": ["core/audit.py", "infrastructure/gcs_lifecycle.yaml"],
      "acceptance_signal": "Audit logs stored in immutable GCS with 7yr lifecycle policy; query shows records from 2018 available",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_066",
      "area": "Data",
      "question": "How do we handle duplicate order_ids from Shopify webhook retries without double-counting revenue?",
      "why_it_matters": "Q_001 dedup for events but not orders; webhook retry caused $80k revenue overcount in weekly report",
      "evidence_anchor": ["agents/ecommerce_agent.py", "core/message_bus.py"],
      "acceptance_signal": "Order ingestion uses order_id as idempotency key; duplicate webhooks result in single revenue record",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_067",
      "area": "Data",
      "question": "What backfill strategy reconciles historical data when upstream API provider fixes past billing errors?",
      "why_it_matters": "Meta corrected spend data retroactively causing MMM trained on wrong baseline; no reprocessing pipeline",
      "evidence_anchor": ["agents/ad_platform_agent.py", "agents/mmm_agent.py"],
      "acceptance_signal": "Backfill agent can reprocess date range; MMM auto-retrains if historical data changes >5%",
      "urgency": "P2",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_068",
      "area": "Features",
      "question": "How do we detect when feature store serves features computed on incomplete data partition?",
      "why_it_matters": "Q_031 MIN_RECORDS but no partition check; partial daily data caused wrong aggregations downstream",
      "evidence_anchor": ["core/feature_store.py", "agents/data_quality.py"],
      "acceptance_signal": "Feature store validates partition completeness before aggregation; rejects incomplete partitions with metric",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_069",
      "area": "Strategy",
      "question": "What prevents budget optimizer from allocating 100% to single highest-ROAS channel ignoring risk diversification?",
      "why_it_matters": "Q_033 brand protection undefined; optimizer concentrated 95% budget in one channel causing platform dependency",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "core/constraints.py"],
      "acceptance_signal": "Budget optimizer enforces max_channel_allocation_pct=40; rejects solutions exceeding concentration limits",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_070",
      "area": "Strategy",
      "question": "How do we validate that Bayesian MMM posterior distributions have converged (R-hat <1.1)?",
      "why_it_matters": "Q_032 calibration undefined; unconverged chains caused unstable coefficient estimates changing ±30% per run",
      "evidence_anchor": ["agents/mmm_agent.py", "SSOT/METRICS/progress.json"],
      "acceptance_signal": "MMM training checks Gelman-Rubin R-hat <1.1; rejects models with poor convergence and logs warning",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_071",
      "area": "Risk",
      "question": "What circuit breaker pattern prevents cascading failures when BigQuery quota is exhausted?",
      "why_it_matters": "Q_036 kill-switch only for campaigns; BQ quota exhaustion caused all agents to fail simultaneously",
      "evidence_anchor": ["core/circuit_breaker.py", "agents/data_quality.py"],
      "acceptance_signal": "Circuit breaker opens after 5 consecutive BQ failures; degraded mode serves cached data with alert",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_072",
      "area": "Execution",
      "question": "How do we prevent activation agent from creating duplicate campaigns when API returns 500 but actually succeeded?",
      "why_it_matters": "Q_014 mutation_id dedup but no idempotency token in API call; transient error caused double campaign creation",
      "evidence_anchor": ["agents/activation_agent.py", "core/contracts.py"],
      "acceptance_signal": "Activation sends platform idempotency token; duplicate API calls result in same campaign_id returned",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_073",
      "area": "RAG",
      "question": "What prevents retriever from returning PII-containing documents to LLM context window?",
      "why_it_matters": "Q_043 source validation but no PII check; RAG retrieved user_mapping doc exposing emails to LLM logs",
      "evidence_anchor": ["agents/retriever_rag.py", "core/security.py"],
      "acceptance_signal": "Retriever filters documents by access_control tags; PII-tagged docs blocked from RAG results",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_074",
      "area": "Governance",
      "question": "How do we audit that every LLM completion was verified by separate Verifier model before use?",
      "why_it_matters": "Q_046 Analyst!=Verifier enforced but no verification audit; cannot prove compliance with council-light design",
      "evidence_anchor": ["core/audit.py", "agents/llm_guardrails.py"],
      "acceptance_signal": "Audit log shows analyst_call_id → verifier_call_id → approved chain; query verifies 100% verification rate",
      "urgency": "P1",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_075",
      "area": "RBAC",
      "question": "What prevents privilege escalation when user with editor role modifies their own RBAC permissions?",
      "why_it_matters": "Q_049 JWT validation but no self-modification check; editor granted themselves admin via API mutation",
      "evidence_anchor": ["core/rbac.py", "infrastructure/api_gateway.py"],
      "acceptance_signal": "RBAC denies permission mutations on self; editor→admin mutation returns 403 with security alert",
      "urgency": "P0",
      "owner_hint": "Governance"
    }
  ]
}
