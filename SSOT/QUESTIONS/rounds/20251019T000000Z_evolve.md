# Question Evolution Round - 20251019T000000Z

## High-Leverage Questions for MBI System

### Q_001: Data Ingestion Idempotency
- **Hypothesis**: Current ad platform ingestion may create duplicate records without proper deduplication
- **Why it matters**: Duplicate spend records inflate MMM/MTA calculations and corrupt attribution
- **Expected impact**: 5-10% variance in ROAS calculations if duplicates exist
- **How to verify**: Create unit tests for SpendRecord ingestion with same (channel, campaign_id, date) tuple; verify single insert
- **Proposed change**: Add unique constraint on (channel, campaign_id, date) in fct_ad_metric_daily; implement upsert logic with ON CONFLICT
- **Targets**: ["src/agents/ingestion/ad_platform_agent.py", "tests/test_ingestion_idempotency.py", "db/schema/fct_ad_metric_daily.sql"]
- **Urgency**: P0
- **Status**: open

### Q_002: Identity Resolution Privacy Compliance
- **Hypothesis**: User key hashing may not comply with GDPR/privacy requirements for data minimization
- **Why it matters**: Non-compliant PII handling risks legal exposure and user trust
- **Expected impact**: Critical compliance gap; potential regulatory penalties
- **How to verify**: Review IdentityResolutionAgent.hash_pii against GDPR Article 32 requirements; verify salt rotation, TTL enforcement
- **Proposed change**: Implement salt rotation schedule, enforce 90-day TTL on hashed identifiers, add audit logging
- **Targets**: ["src/agents/identity/identity_resolution_agent.py", "tests/test_identity_privacy.py", "docs/PRIVACY_COMPLIANCE.md"]
- **Urgency**: P0
- **Status**: open

### Q_003: MMM Model Validation
- **Hypothesis**: Bayesian MMM may not have proper holdout validation or MAPE tracking
- **Why it matters**: Unvalidated models produce unreliable budget recommendations
- **Expected impact**: 20-30% error in allocation if model overfits
- **How to verify**: Check for train/test split, MAPE calculation, model registry with performance tracking
- **Proposed change**: Add 20% holdout set, compute MAPE on validation, reject models with MAPE > 0.15
- **Targets**: ["src/agents/mmm/mmm_agent.py", "tests/test_mmm_validation.py", "src/agents/mmm/model_validator.py"]
- **Urgency**: P0
- **Status**: open

### Q_004: LLM Output Validation
- **Hypothesis**: LLM council outputs may not have strict JSON schema validation before use
- **Why it matters**: Invalid LLM outputs can crash workflows or produce corrupt decisions
- **Expected impact**: System instability, failed playbook executions
- **How to verify**: Check for Pydantic schema validation on all LLM responses before downstream use
- **Proposed change**: Implement LLMGuardrails.validate_llm_output wrapper; enforce min_sources ≥ 2, toxicity checks
- **Targets**: ["src/agents/llm/llm_guardrails.py", "tests/test_llm_validation.py", "src/agents/llm/base_llm_agent.py"]
- **Urgency**: P0
- **Status**: open

### Q_005: Creative Fatigue Detection Algorithm
- **Hypothesis**: Linear regression slope may not capture non-linear fatigue patterns
- **Why it matters**: Missed fatigue signals waste budget on declining creatives
- **Expected impact**: 10-15% wasted spend on fatigued assets
- **How to verify**: Test with synthetic time series showing exponential decay vs linear; compare detection accuracy
- **Proposed change**: Add changepoint detection (e.g., PELT algorithm) to identify fatigue inflection points
- **Targets**: ["src/agents/creative/creative_intelligence_agent.py", "tests/test_fatigue_detection.py"]
- **Urgency**: P1
- **Status**: open

### Q_006: Feature Store Online/Offline Parity
- **Hypothesis**: Feature calculations may differ between offline (dbt) and online (Redis) environments
- **Why it matters**: Train/serve skew degrades model performance in production
- **Expected impact**: 5-15% degradation in live prediction accuracy
- **How to verify**: Create parity tests comparing offline feature output to online for same input
- **Proposed change**: Implement shared feature computation library used by both dbt macros and online service
- **Targets**: ["src/features/feature_engineering_agent.py", "tests/test_feature_parity.py", "dbt/macros/feature_lib.sql"]
- **Urgency**: P1
- **Status**: open

### Q_007: Crisis Detection False Positive Rate
- **Hypothesis**: Velocity-based crisis detection may have high false positive rate
- **Why it matters**: Alert fatigue leads to ignored genuine crises
- **Expected impact**: Reduced response time to real crises
- **How to verify**: Measure precision/recall on historical labeled crisis events
- **Proposed change**: Add multi-source corroboration requirement (≥2 independent sources), official domain verification
- **Targets**: ["src/agents/crisis/crisis_detection_agent.py", "tests/test_crisis_precision.py"]
- **Urgency**: P1
- **Status**: open

### Q_008: Budget Allocation Constraints
- **Hypothesis**: Optimizer may not enforce business constraints (min/max spend per channel)
- **Why it matters**: Unrealistic allocations ignored by stakeholders
- **Expected impact**: Low adoption of automated recommendations
- **How to verify**: Test optimizer with extreme constraints; verify all constraints honored
- **Proposed change**: Add constraint validation layer, reject allocations violating hard limits
- **Targets**: ["src/agents/decision/budget_allocation_agent.py", "tests/test_allocation_constraints.py"]
- **Urgency**: P1
- **Status**: open

### Q_009: Playbook Approval Timeout Handling
- **Hypothesis**: Playbooks may not handle approval timeout gracefully
- **Why it matters**: Stuck playbooks block automation pipeline
- **Expected impact**: System degradation over time
- **How to verify**: Simulate approval timeout; verify playbook state cleanup and retry logic
- **Proposed change**: Add timeout_hours parameter, implement exponential backoff retry, alert on repeated timeouts
- **Targets**: ["src/orchestration/playbook_orchestrator.py", "tests/test_playbook_timeout.py"]
- **Urgency**: P2
- **Status**: open

### Q_010: API Rate Limiting
- **Hypothesis**: Ad platform API calls may not have proper rate limiting and backoff
- **Why it matters**: Rate limit violations cause ingestion failures
- **Expected impact**: Data gaps, incomplete metrics
- **How to verify**: Test with rate-limited mock API; verify exponential backoff implementation
- **Proposed change**: Implement token bucket rate limiter, 429 detection with exponential backoff
- **Targets**: ["src/agents/ingestion/ad_platform_agent.py", "tests/test_rate_limiting.py", "src/utils/rate_limiter.py"]
- **Urgency**: P2
- **Status**: open

### Q_011: Model Drift Detection
- **Hypothesis**: MMM/MTA models may drift over time without automated detection
- **Why it matters**: Stale models produce poor recommendations
- **Expected impact**: 15-25% degradation over 6 months
- **How to verify**: Track MAPE over rolling windows; alert on degradation > 5pp
- **Proposed change**: Add weekly model performance monitoring, auto-trigger retraining on drift
- **Targets**: ["src/agents/monitoring/monitoring_agent.py", "tests/test_drift_detection.py"]
- **Urgency**: P1
- **Status**: open

### Q_012: Secret Management
- **Hypothesis**: API keys may be stored in environment variables without rotation
- **Why it matters**: Static secrets increase breach risk
- **Expected impact**: Critical security vulnerability
- **How to verify**: Audit all API key usage; verify retrieval from secret manager with rotation policy
- **Proposed change**: Migrate all secrets to GCP Secret Manager / AWS Secrets Manager with auto-rotation
- **Targets**: ["src/config/secrets.py", "tests/test_secret_rotation.py", "terraform/main.tf"]
- **Urgency**: P0
- **Status**: open

### Q_013: Database Connection Pooling
- **Hypothesis**: PostgreSQL connections may not use pooling, causing exhaustion under load
- **Why it matters**: Connection exhaustion crashes agents
- **Expected impact**: System instability in production
- **How to verify**: Load test with concurrent queries; monitor connection count
- **Proposed change**: Implement pgbouncer or SQLAlchemy pooling with max_overflow limits
- **Targets**: ["src/db/connection.py", "tests/test_connection_pool.py", "k8s/deployment.yaml"]
- **Urgency**: P1
- **Status**: open

### Q_014: Event Schema Versioning
- **Hypothesis**: Kafka events may lack schema versioning, breaking consumers on changes
- **Why it matters**: Schema changes cause pipeline failures
- **Expected impact**: Downtime during deployments
- **How to verify**: Test schema evolution (add field, remove field, change type); verify backward compatibility
- **Proposed change**: Implement Avro schemas with compatibility checks in schema registry
- **Targets**: ["src/events/schemas.py", "tests/test_schema_evolution.py", "src/events/producer.py"]
- **Urgency**: P1
- **Status**: open

### Q_015: Metrics Aggregation Accuracy
- **Hypothesis**: Pre-aggregated metrics in marts may have rounding errors vs raw data
- **Why it matters**: Executive dashboards show inconsistent numbers
- **Expected impact**: Loss of stakeholder trust
- **How to verify**: Reconcile mart aggregates against raw fact tables; measure discrepancy
- **Proposed change**: Use higher precision (NUMERIC vs FLOAT), add reconciliation tests
- **Targets**: ["dbt/models/marts/mkt_perf__roas_by_channel.sql", "tests/test_metric_reconciliation.py"]
- **Urgency**: P2
- **Status**: open
