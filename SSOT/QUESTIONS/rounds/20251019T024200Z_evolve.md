{
  "questions": [
    {
      "id": "Q_067",
      "area": "Data",
      "question": "Does GA4 BigQuery export schema validation detect breaking changes within 1 hour of upstream drift?",
      "why_it_matters": "C02_DataQuality Red; schema drift (A_010) causes downstream pipeline failures; CRITICAL data quality gate",
      "evidence_anchor": ["agents/analytics_agent.py", "tests/agents/test_analytics_schema_drift.py", "SSOT/COVERAGE/coverage.matrix.csv"],
      "acceptance_signal": "Test schema_drift_detected_within_1h passes; metric schema_drift_detection_latency_minutes <60; CI fails on missing validator",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_068",
      "area": "Data",
      "question": "Are ingestion SLA violations (>6h lag) automatically pausing dependent downstream agents to prevent stale decisions?",
      "why_it_matters": "C02_DataQuality Red; freshness SLA (A_012) unmonitored; MMM/MTA on 24h-old data compromises accuracy",
      "evidence_anchor": ["agents/data_quality_agent.py", "tests/agents/test_freshness_sla.py"],
      "acceptance_signal": "Test downstream_pause_on_stale_data passes; metric freshness_sla_violations triggers pause; zero stale decisions 7d",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_069",
      "area": "Features",
      "question": "Does feature store online/offline skew trigger alerts when batch vs streaming values differ by >1% for same entity_id?",
      "why_it_matters": "C03_FeatureEngineering Red; Q_043/Q_066/A_008 CRITICAL; training/serving parity essential for model reliability",
      "evidence_anchor": ["core/feature_store.py", "tests/core/test_feature_store_online_offline_parity.py"],
      "acceptance_signal": "Test parity_check_alerts_on_1pct_skew passes; metric feature_skew_pct <1.0; daily parity validation CI job",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_070",
      "area": "Features",
      "question": "Is feature store write path idempotent with feature_key + timestamp uniqueness enforced at DB level?",
      "why_it_matters": "C03_FeatureEngineering Red; duplicate features from retries corrupt aggregations; idempotency CRITICAL",
      "evidence_anchor": ["core/feature_store.py", "tests/core/test_feature_store_idempotency.py"],
      "acceptance_signal": "Test duplicate_feature_rejected passes; DB constraint (feature_key, timestamp) unique; metric duplicate_features_rejected",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_071",
      "area": "Strategy",
      "question": "Does MMM agent validate seasonality controls (holidays, weather, events) are present before model training?",
      "why_it_matters": "C04_MMM Red; A_009 missing seasonality; omitted controls bias attribution and ROI estimates",
      "evidence_anchor": ["agents/mmm_agent.py", "tests/agents/test_mmm_seasonality_controls.py"],
      "acceptance_signal": "Test training_rejects_missing_seasonality passes; config schema requires controls; metric mmm_training_validation_failures",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_072",
      "area": "Strategy",
      "question": "Are MMM posterior samples persisted in model registry with trace metadata for reproducibility and audit trails?",
      "why_it_matters": "C04_MMM Red; Bayesian trace lost after training; regulatory audit requires model lineage and versioning",
      "evidence_anchor": ["agents/mmm_agent.py", "models/model_registry.py", "tests/agents/test_mmm_model_versioning.py"],
      "acceptance_signal": "Test mmm_trace_persisted_with_metadata passes; model_registry.get_trace(model_id) succeeds; 7yr retention",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_073",
      "area": "Strategy",
      "question": "Does MTA agent enforce differential privacy noise addition for paths with <10 users before aggregation?",
      "why_it_matters": "C05_MTA Red; Q_046 CRITICAL privacy violation; <10 users per path risks re-identification under GDPR",
      "evidence_anchor": ["agents/mta_agent.py", "tests/agents/test_mta_privacy.py"],
      "acceptance_signal": "Test paths_below_10_users_dropped_or_noised passes; metric privacy_violations=0; MTA only outputs aggregated paths",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_074",
      "area": "Strategy",
      "question": "Is MTA attribution normalized to sum to 1.0 within ±0.01 tolerance to prevent allocation budget errors?",
      "why_it_matters": "C05_MTA Red; non-normalized weights cause over/under-allocation; budget reconciliation failures downstream",
      "evidence_anchor": ["agents/mta_agent.py", "tests/agents/test_mta_normalization.py"],
      "acceptance_signal": "Test attribution_sum_equals_1 passes; assertion abs(sum(weights) - 1.0) < 0.01; CI enforces",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_075",
      "area": "Strategy",
      "question": "Does Incrementality agent validate geo-experiment matched pairs have <10% pre-period revenue variance before launch?",
      "why_it_matters": "C06_Incrementality Red; poor matching invalidates causal inference; parallel trends assumption violated",
      "evidence_anchor": ["agents/incrementality_agent.py", "tests/agents/test_incrementality_matching.py"],
      "acceptance_signal": "Test matching_variance_below_10pct passes; experiment design rejected if variance >10%; metric experiment_design_failures",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_076",
      "area": "Strategy",
      "question": "Are brand tracking metrics (SoS, SOV, brand lift) refreshed daily with <24h lag and stale data alerts?",
      "why_it_matters": "C07_BrandTracking Red; no observability; crisis detection relies on timely brand metrics; >24h lag misses events",
      "evidence_anchor": ["agents/brand_tracking_agent.py", "tests/agents/test_brand_tracking_freshness.py"],
      "acceptance_signal": "Test brand_metrics_refreshed_daily passes; metric brand_metrics_lag_hours <24; alert on >24h",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_077",
      "area": "Strategy",
      "question": "Does creative asset fingerprinting detect duplicate uploads within 1% perceptual hash similarity to prevent re-testing?",
      "why_it_matters": "C08_CreativeIntelligence Red; A_018 missing; duplicate assets waste test budget and dilute learnings",
      "evidence_anchor": ["agents/creative_intelligence_agent.py", "tests/agents/test_creative_dedup.py"],
      "acceptance_signal": "Test duplicate_asset_rejected_1pct_similarity passes; metric duplicate_assets_prevented; pHash <1% similarity threshold",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_078",
      "area": "Strategy",
      "question": "Are creative fatigue scores computed using exponential moving average (EMA) to detect sudden CTR drops within 48h?",
      "why_it_matters": "C08_CreativeIntelligence Red; linear regression too slow; rapid fatigue (48h) requires real-time EMA detection",
      "evidence_anchor": ["agents/creative_intelligence_agent.py", "tests/agents/test_creative_fatigue_ema.py"],
      "acceptance_signal": "Test ema_detects_fatigue_within_48h passes; EMA span=3d; alert on fatigue_score >0.7 within 48h",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_079",
      "area": "Strategy",
      "question": "Does audience clustering agent enforce minimum cluster size of 10,000 users to maintain privacy and statistical power?",
      "why_it_matters": "C09_AudienceClustering Red; small clusters risk re-identification; <10k users insufficient for reliable targeting",
      "evidence_anchor": ["agents/audience_clustering_agent.py", "tests/agents/test_audience_clustering_privacy.py"],
      "acceptance_signal": "Test min_cluster_size_10k enforced passes; clusters <10k dropped; metric small_clusters_dropped",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_080",
      "area": "Strategy",
      "question": "Is LLM Council temperature enforcement validated at FastAPI middleware layer before every completion call?",
      "why_it_matters": "C10_LLMCouncil Red; Q_049 CRITICAL; temperature >0.2 bypasses determinism guarantees; runtime enforcement essential",
      "evidence_anchor": ["middleware/llm_guard.py", "tests/middleware/test_llm_temperature_guard.py"],
      "acceptance_signal": "Test temperature_guard_rejects_over_0_2 passes; middleware blocks requests; metric llm_temperature_violations=0",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_081",
      "area": "Strategy",
      "question": "Does LLM Council Verifier model use separate API key and endpoint to prevent cache poisoning between Analyst and Verifier?",
      "why_it_matters": "C10_LLMCouncil Red; Q_047 CRITICAL; shared cache defeats independent verification; key separation enforces isolation",
      "evidence_anchor": ["agents/llm_council.py", "config/llm_config.yaml", "tests/agents/test_llm_council_isolation.py"],
      "acceptance_signal": "Test verifier_uses_separate_api_key passes; config enforces different endpoints; metric cache_isolation_enforced=1",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_082",
      "area": "Risk",
      "question": "Does Crisis Detection agent require >=2 independent sources AND >=1 official domain before risk_score can exceed 0.5?",
      "why_it_matters": "C11_CrisisDetection Red; Q_050 CRITICAL; single unverified source false positives pause campaigns; dual-gate prevents",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "tests/agents/test_crisis_source_validation.py"],
      "acceptance_signal": "Test risk_capped_0_5_without_dual_sources passes; metric crisis_low_confidence; zero high-risk single-source 30d",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_083",
      "area": "Risk",
      "question": "Are Crisis Detection stance labels (against/for/neutral/unclear) validated against enum schema to prevent undefined states?",
      "why_it_matters": "C11_CrisisDetection Red; undefined stance breaks downstream decision logic; Pydantic enum enforces contract",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "schemas/crisis_brief.py", "tests/agents/test_crisis_stance_enum.py"],
      "acceptance_signal": "Test invalid_stance_rejected passes; Pydantic enum StanceType; metric invalid_stance_attempts=0",
      "urgency": "P1",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_084",
      "area": "Compliance",
      "question": "Does Compliance Agent block content submission if Japan market and 'Promo/広告' label missing from text field?",
      "why_it_matters": "C12_ComplianceAgent Red; Q_052 CRITICAL; Japan law requires disclosure; missing label violates regulations",
      "evidence_anchor": ["agents/compliance_agent.py", "tests/agents/test_compliance_promo_label_japan.py"],
      "acceptance_signal": "Test japan_promo_requires_label passes; regex validates label presence; metric promo_label_violations=0; CI blocks",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_085",
      "area": "Compliance",
      "question": "Is age gate enforcement (<18 block) validated at API gateway layer with JWT age claim before reaching business logic?",
      "why_it_matters": "C12_ComplianceAgent Red; Q_051 CRITICAL; minor access to promo violates COPPA; defense-in-depth at gateway",
      "evidence_anchor": ["middleware/compliance_guard.py", "tests/middleware/test_age_gate.py"],
      "acceptance_signal": "Test age_under_18_returns_403_at_gateway passes; JWT age claim validated; metric minor_access_blocked",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_086",
      "area": "Execution",
      "question": "Does Budget Allocation agent enforce ROAS threshold (e.g., >=2.0) as hard constraint in optimization to prevent unprofitable channels?",
      "why_it_matters": "C13_BudgetAllocation Red; unconstrained optimization allocates to low-ROAS channels; threshold prevents loss",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_roas_constraint.py"],
      "acceptance_signal": "Test roas_constraint_enforced passes; scipy.optimize bounds ROAS >=2.0; metric low_roas_allocations_rejected",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_087",
      "area": "Execution",
      "question": "Is budget allocation_id a deterministic hash of (week_start, channel_mix, total_budget) to ensure idempotency on retry?",
      "why_it_matters": "C13_BudgetAllocation Red; Q_054 done but verify hash determinism; UUID would break idempotency",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_allocation_id_hash.py"],
      "acceptance_signal": "Test allocation_id_deterministic_hash passes; hashlib.sha256(canonical_inputs); same inputs = same ID",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_088",
      "area": "Execution",
      "question": "Does Pacing Agent daily spend forecasting use EMA (last 7 days) to detect sudden over-pacing within 24 hours?",
      "why_it_matters": "C14_PacingAgent Red; no artifacts; monthly budget blown in 3 days; EMA triggers early alerts",
      "evidence_anchor": ["agents/pacing_agent.py", "tests/agents/test_pacing_ema_forecast.py"],
      "acceptance_signal": "Test pacing_alert_within_24h_overspend passes; EMA span=7d; alert if forecast >110% daily target",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_089",
      "area": "Execution",
      "question": "Are Pacing Agent CPA target violations (actual >110% target) automatically triggering bid reduction within 1 hour?",
      "why_it_matters": "C14_PacingAgent Red; manual intervention slow; automated bid reduction prevents runaway costs",
      "evidence_anchor": ["agents/pacing_agent.py", "tests/agents/test_pacing_auto_bid_reduction.py"],
      "acceptance_signal": "Test auto_bid_reduction_on_cpa_violation passes; bid reduced 10% if CPA >110% target; metric pacing_auto_corrections",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_090",
      "area": "Execution",
      "question": "Does Creative Rotation agent enforce max 3 concurrent A/B tests per campaign to prevent statistical dilution?",
      "why_it_matters": "C15_CreativeRotation Red; >3 tests split traffic too thin; inconclusive results waste budget",
      "evidence_anchor": ["agents/creative_rotation_agent.py", "tests/agents/test_creative_ab_test_limit.py"],
      "acceptance_signal": "Test max_3_concurrent_tests passes; 4th test rejected; metric ab_test_limit_violations; config MAX_CONCURRENT_TESTS=3",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_091",
      "area": "Execution",
      "question": "Is Creative Rotation fatigue threshold (0.7) tunable per campaign via config without code deploy?",
      "why_it_matters": "C15_CreativeRotation Red; hardcoded threshold prevents experimentation; different verticals need different thresholds",
      "evidence_anchor": ["agents/creative_rotation_agent.py", "config/campaigns.yaml", "tests/agents/test_creative_fatigue_threshold_config.py"],
      "acceptance_signal": "Test fatigue_threshold_from_config passes; campaigns.yaml overrides default 0.7; hot-reload without restart",
      "urgency": "P2",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_092",
      "area": "Execution",
      "question": "Does Playbook Orchestrator approval timeout (24h) auto-escalate to manager if no response within 12h?",
      "why_it_matters": "C16_PlaybookOrchestrator Red; A_011 MINOR but time-sensitive; 24h timeout too long; 12h escalation speeds decisions",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "tests/agents/test_playbook_approval_escalation.py"],
      "acceptance_signal": "Test escalates_after_12h_no_response passes; Slack notification to manager; metric approval_escalations",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_093",
      "area": "Execution",
      "question": "Are Playbook dry-run executions tagged with dry_run=true in audit logs to separate from production actions?",
      "why_it_matters": "C16_PlaybookOrchestrator Red; dry-run vs prod distinction missing; audit compliance requires clear separation",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "core/audit.py", "tests/agents/test_playbook_dry_run_tagging.py"],
      "acceptance_signal": "Test dry_run_tagged_in_audit_log passes; audit_log.dry_run boolean field; metric dry_run_executions",
      "urgency": "P2",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_094",
      "area": "Execution",
      "question": "Does Activation Agent request_id use UUID v4 + timestamp prefix to guarantee uniqueness and temporal ordering?",
      "why_it_matters": "C17_ActivationAgent Red; Q_031 done but verify UUID collision resistance; timestamp prefix aids debugging",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_request_id_format.py"],
      "acceptance_signal": "Test request_id_format_uuid_v4_with_timestamp passes; format YYYYMMDD_HHMMSS_<uuid4>; zero collisions 30d",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_095",
      "area": "Execution",
      "question": "Are Activation Agent API mutations logged with before/after state snapshots for audit and rollback capability?",
      "why_it_matters": "C17_ActivationAgent Red; rollback requires state snapshot; regulatory audit needs mutation history",
      "evidence_anchor": ["agents/activation_agent.py", "core/audit.py", "tests/agents/test_activation_audit_snapshots.py"],
      "acceptance_signal": "Test mutation_logged_with_snapshots passes; audit_log.before_state and after_state JSON; 7yr retention",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_096",
      "area": "Compliance",
      "question": "Does Policy Agent validate medical/health claims against banned_claims.json before allowing creative submission?",
      "why_it_matters": "C18_PolicyAgent Red; medical claims violate ad platform policies; pre-submission validation prevents rejections",
      "evidence_anchor": ["agents/policy_agent.py", "config/banned_claims.json", "tests/agents/test_policy_medical_claims.py"],
      "acceptance_signal": "Test medical_claim_rejected passes; regex match against banned list; metric policy_violations; CI fails",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_097",
      "area": "Compliance",
      "question": "Is Policy Agent promo label enforcement (Promo/広告) applied to all locales (ja, vi, zh, ko, en) with locale-specific regex?",
      "why_it_matters": "C18_PolicyAgent Red; Q_052 only covers Japan; Vietnam/China/Korea have similar disclosure laws",
      "evidence_anchor": ["agents/policy_agent.py", "config/promo_label_rules.yaml", "tests/agents/test_policy_multilingual_labels.py"],
      "acceptance_signal": "Test promo_label_all_locales passes; locale-specific regex; metric label_violations_by_locale; zero violations",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_098",
      "area": "Observability",
      "question": "Does Monitoring Agent emit P0 alerts to PagerDuty within 2 minutes of SLO breach (e.g., kill_switch_halt >5s)?",
      "why_it_matters": "C19_MonitoringAgent Red; no artifacts; delayed alerts extend MTTR; 2min SLA critical for P0",
      "evidence_anchor": ["agents/monitoring_agent.py", "tests/agents/test_monitoring_p0_alert_latency.py"],
      "acceptance_signal": "Test p0_alert_within_2min passes; PagerDuty API call <2min; metric alert_latency_p0_seconds <120",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_099",
      "area": "Observability",
      "question": "Are Monitoring Agent anomaly detection baselines retrained weekly to adapt to traffic pattern changes (seasonality)?",
      "why_it_matters": "C19_MonitoringAgent Red; static baselines cause false positives during holidays; weekly retrain reduces noise",
      "evidence_anchor": ["agents/monitoring_agent.py", "tests/agents/test_monitoring_baseline_retrain.py"],
      "acceptance_signal": "Test baseline_retrained_weekly passes; Prefect schedule @weekly; metric baseline_staleness_days <7",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_100",
      "area": "Compliance",
      "question": "Does Audit Agent enforce write-once semantics (append-only, no UPDATE/DELETE) at database constraint level?",
      "why_it_matters": "C20_AuditAgent Red; A_015 MAJOR; immutability requires DB constraint not just app logic; SOX compliance",
      "evidence_anchor": ["core/audit.py", "migrations/audit_log_table.sql", "tests/core/test_audit_immutability.py"],
      "acceptance_signal": "Test audit_log_no_update_allowed passes; DB trigger blocks UPDATE/DELETE; metric audit_mutation_attempts=0",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_101",
      "area": "Compliance",
      "question": "Is Audit Log 7-year retention policy enforced via BigQuery table expiration at 2555 days (7*365)?",
      "why_it_matters": "C20_AuditAgent Red; A_015 MAJOR; GDPR/SOX require 7yr retention; auto-expiration prevents manual deletion errors",
      "evidence_anchor": ["infrastructure/bigquery_tables.tf", "tests/infra/test_audit_log_retention.py"],
      "acceptance_signal": "Test audit_log_retention_7yr passes; BQ table expiration 2555 days; metric audit_log_oldest_record_days <2555",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_102",
      "area": "Infra",
      "question": "Does Circuit Breaker reset to CLOSED state after 60s half-open trial period with 1 successful request?",
      "why_it_matters": "Infra_ExternalAPIs Red; Q_055 done but verify recovery logic; stuck OPEN circuit blocks valid requests",
      "evidence_anchor": ["infrastructure/circuit_breaker.py", "tests/infra/test_circuit_breaker_recovery.py"],
      "acceptance_signal": "Test circuit_recovers_after_60s_success passes; half-open → closed transition; metric circuit_recovery_time_seconds",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_103",
      "area": "Infra",
      "question": "Are Circuit Breaker failure thresholds (3 consecutive) configurable per external API (Meta, Google, TikTok) without code change?",
      "why_it_matters": "Infra_ExternalAPIs Red; different APIs have different reliability; hardcoded threshold prevents tuning",
      "evidence_anchor": ["infrastructure/circuit_breaker.py", "config/external_apis.yaml", "tests/infra/test_circuit_breaker_config.py"],
      "acceptance_signal": "Test circuit_threshold_from_config passes; external_apis.yaml per-API threshold; hot-reload without restart",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_104",
      "area": "Infra",
      "question": "Does Rate Limiter use sliding window (not fixed window) to prevent burst at window boundaries?",
      "why_it_matters": "Infra_ExternalAPIs Red; Q_056 done but fixed window allows 200 req in 2min at boundary; sliding prevents",
      "evidence_anchor": ["infrastructure/rate_limiter.py", "tests/infra/test_rate_limiter_sliding_window.py"],
      "acceptance_signal": "Test sliding_window_prevents_boundary_burst passes; Redis ZSET sliding window; metric boundary_burst_prevented",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_105",
      "area": "Infra",
      "question": "Is OpenTelemetry trace context propagated in async tasks (Celery/Prefect) to maintain E2E trace continuity?",
      "why_it_matters": "Infra_Observability Red; Q_035 done but async tasks may lose context; broken traces make debugging impossible",
      "evidence_anchor": ["infrastructure/otel.py", "middleware/tracing.py", "tests/infra/test_otel_async_context.py"],
      "acceptance_signal": "Test trace_context_propagates_async passes; Prefect/Celery carry trace_id; metric trace_continuity_rate >=0.99",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_106",
      "area": "Infra",
      "question": "Does distributed tracing sampling rate adjust dynamically (10% normal, 100% on errors) to reduce overhead while capturing failures?",
      "why_it_matters": "Infra_Observability Red; 100% sampling adds 50ms latency; adaptive sampling balances cost and debugging",
      "evidence_anchor": ["infrastructure/otel.py", "tests/infra/test_otel_adaptive_sampling.py"],
      "acceptance_signal": "Test adaptive_sampling_on_errors passes; normal 10%, error 100%; metric trace_sampling_rate_pct",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_107",
      "area": "RBAC",
      "question": "Is JWT role claim ('ad-ops', 'pii-admin', 'admin') validated against enum schema to prevent typo-based privilege escalation?",
      "why_it_matters": "Infra_Auth Red; Q_036 done but typo 'admn' might bypass checks; enum validation prevents",
      "evidence_anchor": ["middleware/auth.py", "schemas/jwt_claims.py", "tests/middleware/test_jwt_role_enum.py"],
      "acceptance_signal": "Test invalid_role_rejected passes; Pydantic RoleEnum; metric invalid_role_attempts=0",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_108",
      "area": "RBAC",
      "question": "Does JWT token expiration (e.g., 1h) trigger refresh flow 5 minutes before expiry to prevent mid-request failures?",
      "why_it_matters": "Infra_Auth Red; expired token mid-request causes 401 errors; proactive refresh improves UX",
      "evidence_anchor": ["middleware/auth.py", "tests/middleware/test_jwt_refresh_proactive.py"],
      "acceptance_signal": "Test jwt_refresh_5min_before_expiry passes; refresh triggered at exp - 300s; metric token_refresh_failures=0",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_109",
      "area": "RBAC",
      "question": "Is PII mapping table access logged in audit trail with (user, timestamp, query_hash) to detect unauthorized queries?",
      "why_it_matters": "Infra_Auth Red; Q_058 done but access logging missing; GDPR requires PII access audit trail",
      "evidence_anchor": ["core/rbac.py", "core/audit.py", "tests/core/test_pii_access_audit.py"],
      "acceptance_signal": "Test pii_access_logged passes; audit_log.pii_access_event; metric pii_access_queries_count; 7yr retention",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_110",
      "area": "Secrets",
      "question": "Does Secret Manager client retry with exponential backoff (3 retries, max 5s) to handle transient API failures?",
      "why_it_matters": "DataOps_Secrets Red; Q_037 done but no retry; transient failures cause boot failures; retry improves reliability",
      "evidence_anchor": ["core/security.py", "tests/core/test_secret_manager_retry.py"],
      "acceptance_signal": "Test secret_manager_retries_3_times passes; tenacity exponential backoff max 5s; metric secret_fetch_failures",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_111",
      "area": "Secrets",
      "question": "Are hardcoded secrets detected via pre-commit hook (detect-secrets) to block commits before CI?",
      "why_it_matters": "DataOps_Secrets Red; Q_037 CI check too late; pre-commit prevents secrets from entering repo history",
      "evidence_anchor": [".pre-commit-config.yaml", "tests/infra/test_precommit_secret_detection.py"],
      "acceptance_signal": "Test precommit_blocks_hardcoded_secrets passes; detect-secrets baseline updated; metric secrets_blocked_at_commit",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_112",
      "area": "CI/CD",
      "question": "Does CI pipeline fail fast (exit on first test failure) to reduce feedback time from 15min to <5min?",
      "why_it_matters": "CI_CD Red; slow feedback delays fixes; fail-fast improves developer velocity",
      "evidence_anchor": [".github/workflows/ci.yml", "tests/infra/test_ci_fail_fast.py"],
      "acceptance_signal": "Test ci_fails_on_first_test_failure passes; pytest --exitfirst; metric ci_feedback_time_minutes <5",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_113",
      "area": "CI/CD",
      "question": "Are green tests enforced as deployment gate with 100% pass rate required before prod deploy?",
      "why_it_matters": "CI_CD Red; flaky tests allowed to prod; 100% pass rate prevents regressions",
      "evidence_anchor": [".github/workflows/deploy.yml", "tests/infra/test_deploy_gate.py"],
      "acceptance_signal": "Test deploy_requires_100pct_pass passes; GitHub Actions gate; metric failed_deploys_due_to_tests=0",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_114",
      "area": "CI/CD",
      "question": "Does deployment rollback trigger automatically if post-deploy health check fails within 5 minutes?",
      "why_it_matters": "CI_CD Red; manual rollback slow (30min MTTR); auto-rollback reduces to <5min",
      "evidence_anchor": ["infrastructure/k8s/health_check.yaml", "tests/infra/test_auto_rollback.py"],
      "acceptance_signal": "Test auto_rollback_on_health_check_failure passes; K8s readiness probe; metric auto_rollback_count",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_115",
      "area": "Data",
      "question": "Does multi-currency revenue aggregation use daily FX rates from ECB API with 24h cache to ensure accuracy?",
      "why_it_matters": "DataOps_Revenue Red; A_016 missing; hardcoded FX rates drift; daily updates maintain accuracy",
      "evidence_anchor": ["core/revenue.py", "tests/core/test_revenue_multi_currency.py"],
      "acceptance_signal": "Test daily_fx_rates_from_ecb passes; Redis 24h cache; metric fx_rate_staleness_hours <24",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_116",
      "area": "Data",
      "question": "Is revenue reconciliation (Shopify vs internal DB) automated daily with <1% tolerance threshold and alerts on mismatch?",
      "why_it_matters": "DataOps_Revenue Red; manual reconciliation error-prone; automated check catches double-counting/missing orders",
      "evidence_anchor": ["agents/revenue_reconciliation_agent.py", "tests/agents/test_revenue_reconciliation.py"],
      "acceptance_signal": "Test revenue_reconciliation_daily passes; tolerance <1%; alert on mismatch; metric revenue_discrepancy_pct",
      "urgency": "P1",
      "owner_hint": "DataOps"
    }
  ]
}
