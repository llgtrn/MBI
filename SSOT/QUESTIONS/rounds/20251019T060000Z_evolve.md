{
  "questions": [
    {
      "id": "Q_001",
      "area": "Data",
      "question": "Event deduplication: Does event_id uniqueness constraint prevent duplicate revenue counting across retries?",
      "why_it_matters": "C01 Red; Q_063 CRITICAL; duplicate events double revenue; impacts MMM/MTA attribution accuracy",
      "evidence_anchor": ["core/identity.py", "tests/core/test_event_dedup.py", "schemas/event.py"],
      "acceptance_signal": "Test duplicate event_id rejected; metric duplicate_events_rejected >0; zero duplicates in 7d query",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_002",
      "area": "Data",
      "question": "Salt rotation schedule: Is PII salt rotated every 90d with dual-validity window to prevent user_key breaks?",
      "why_it_matters": "C01 Red; Q_064 CRITICAL; GDPR requires rotation; no dual-valid breaks identity resolution",
      "evidence_anchor": ["core/security.py", "tests/core/test_salt_rotation_90d.py"],
      "acceptance_signal": "Test salt_rotates_90d passes; metric days_since_last_rotation <90; dual-valid 24h window",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_003",
      "area": "Data",
      "question": "Schema drift detection: Does GA4 schema change trigger alert within 1h before downstream failures cascade?",
      "why_it_matters": "C02 Red; A_010 MAJOR; unmonitored drift causes silent data loss; impacts all downstream agents",
      "evidence_anchor": ["agents/analytics_agent.py", "tests/agents/test_schema_drift.py"],
      "acceptance_signal": "Test schema_drift_alert_1h passes; metric drift_detected_minutes <60; CI validates",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_004",
      "area": "Data",
      "question": "Freshness SLA enforcement: Does data >6h old automatically pause dependent MMM/MTA pipelines?",
      "why_it_matters": "C02 Red; A_012 MAJOR; stale data produces wrong attribution; automated halt prevents bad decisions",
      "evidence_anchor": ["agents/data_quality_agent.py", "tests/agents/test_freshness_sla.py"],
      "acceptance_signal": "Test downstream_pause_on_stale passes; metric triggers pause; zero stale processing 7d",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_005",
      "area": "Features",
      "question": "Feature Store parity test: Do online and offline features match within 1% for same (entity, timestamp)?",
      "why_it_matters": "C03 Red; Q_043/Q_066/A_008 CRITICAL; training/serving skew causes model drift; daily validation required",
      "evidence_anchor": ["core/feature_store.py", "tests/core/test_feature_parity.py"],
      "acceptance_signal": "Test online_offline_parity_1pct passes; metric feature_skew <1%; daily CI check",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_006",
      "area": "Features",
      "question": "Feature write idempotency: Is (feature_key, entity_id, timestamp) unique to prevent retry aggregation corruption?",
      "why_it_matters": "C03 Red; Q_070 CRITICAL; duplicate feature writes double aggregations; breaks MMM/MTA inputs",
      "evidence_anchor": ["core/feature_store.py", "tests/core/test_feature_idempotency.py", "migrations/feature_unique_constraint.sql"],
      "acceptance_signal": "Test duplicate_feature_rejected passes; DB unique constraint enforced; metric rejections logged",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_007",
      "area": "Features",
      "question": "Feature skew alerting: Does >1% divergence between online/offline trigger automatic investigation workflow?",
      "why_it_matters": "C03 Red; Q_069 CRITICAL; skew indicates pipeline bug; early detection prevents model degradation",
      "evidence_anchor": ["agents/monitoring_agent.py", "tests/agents/test_feature_skew_alert.py"],
      "acceptance_signal": "Test parity_alert_1pct_skew passes; metric <1% threshold; daily automated check",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_008",
      "area": "Strategy",
      "question": "MMM seasonality controls: Are holiday/promo/weather controls validated against historical actuals in training?",
      "why_it_matters": "C04 Red; A_009 gap; missing controls inflate channel ROI; wrong budget allocation",
      "evidence_anchor": ["agents/mmm_agent.py", "tests/agents/test_mmm_seasonality.py"],
      "acceptance_signal": "Test seasonality_controls_validated passes; residuals uncorrelated with holiday indicators",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_009",
      "area": "Strategy",
      "question": "MMM holdout validation: Is MAPE <15% on last 8 weeks holdout before model deployment to production?",
      "why_it_matters": "C04 Red; no validation gate; poor model produces wrong ROI curves; bad budget decisions",
      "evidence_anchor": ["agents/mmm_agent.py", "tests/agents/test_mmm_validation.py"],
      "acceptance_signal": "Test mmm_holdout_mape_15pct passes; deployment blocked if MAPE >=15%",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_010",
      "area": "Strategy",
      "question": "MTA path privacy: Are paths with <10 users dropped/noised before attribution to prevent re-identification?",
      "why_it_matters": "C05 Red; Q_046/Q_073 CRITICAL; <10 violates differential privacy; GDPR re-identification risk",
      "evidence_anchor": ["agents/mta_agent.py", "tests/agents/test_mta_privacy.py"],
      "acceptance_signal": "Test paths_below_10_dropped passes; metric privacy_violations=0; aggregated paths only",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_011",
      "area": "Strategy",
      "question": "Incrementality geo-matching: Do test/control markets match on pre-period revenue Â±5% for valid causal inference?",
      "why_it_matters": "C06 Red; no matching validation; biased pairs produce wrong incrementality; wrong channel ROI",
      "evidence_anchor": ["agents/incrementality_agent.py", "tests/agents/test_geo_matching.py"],
      "acceptance_signal": "Test geo_match_5pct_pre_period passes; synthetic control backup if parallel trends fail",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_012",
      "area": "Strategy",
      "question": "Brand lift survey weighting: Are respondent demographics weighted to match target audience for unbiased lift?",
      "why_it_matters": "C07 Red; no weighting; self-selection bias inflates lift; wrong brand health assessment",
      "evidence_anchor": ["agents/brand_tracking_agent.py", "tests/agents/test_brand_lift_weighting.py"],
      "acceptance_signal": "Test survey_weighted_to_target passes; chi-square test p>0.05 for demo match",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_013",
      "area": "Strategy",
      "question": "Creative asset fingerprinting: Is perceptual hash computed for duplicate detection across campaigns?",
      "why_it_matters": "C08 Red; A_018 gap; duplicate creatives inflate fatigue score; wrong rotation decisions",
      "evidence_anchor": ["agents/creative_intelligence_agent.py", "tests/agents/test_asset_fingerprint.py"],
      "acceptance_signal": "Test perceptual_hash_dedup passes; dHash/pHash similarity >95% flags duplicates",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_014",
      "area": "Strategy",
      "question": "Audience cluster stability: Do clusters remain stable (ARI >0.8) across weekly re-runs for consistent targeting?",
      "why_it_matters": "C09 Red; unstable clusters cause targeting thrash; user experience degrades",
      "evidence_anchor": ["agents/audience_clustering_agent.py", "tests/agents/test_cluster_stability.py"],
      "acceptance_signal": "Test cluster_stability_ari_0.8 passes; Adjusted Rand Index >0.8 week-over-week",
      "urgency": "P1",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_015",
      "area": "Strategy",
      "question": "LLM temperature enforcement: Does middleware reject LLM calls with temperature >0.2 at runtime?",
      "why_it_matters": "C10 Red; Q_049/Q_080 CRITICAL; >0.2 breaks determinism; non-reproducible decisions violate audit",
      "evidence_anchor": ["middleware/llm_guard.py", "tests/middleware/test_llm_temperature_guard.py"],
      "acceptance_signal": "Test temperature_guard_blocks_0.3 passes; metric violations=0; runtime enforcement",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_016",
      "area": "Strategy",
      "question": "LLM source validation: Are outputs with <2 source_ids rejected before entering SSOT to prevent hallucination?",
      "why_it_matters": "C10 Red; Q_048 CRITICAL; single-source allows hallucination; wrong brand intelligence",
      "evidence_anchor": ["agents/llm_council.py", "tests/agents/test_llm_source_validation.py"],
      "acceptance_signal": "Test source_ids_min_2 passes; metric llm_insufficient_sources; zero <2 outputs accepted",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_017",
      "area": "Strategy",
      "question": "Verifier model isolation: Do Analyst and Verifier use different API keys/endpoints to prevent cache poisoning?",
      "why_it_matters": "C10 Red; Q_047/Q_081 CRITICAL; shared cache defeats verification; model separation required",
      "evidence_anchor": ["agents/llm_council.py", "tests/agents/test_llm_council_isolation.py"],
      "acceptance_signal": "Test verifier_separate_key passes; config enforces different endpoints; metric isolation=1",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_018",
      "area": "Strategy",
      "question": "Crisis risk capping: Is risk_score capped at 0.5 when sources <2 to prevent false campaign pauses?",
      "why_it_matters": "C11 Red; Q_050/Q_082 CRITICAL; single-source false alarm pauses revenue campaigns",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "tests/agents/test_crisis_source_validation.py"],
      "acceptance_signal": "Test risk_cap_0.5_single_source passes; metric low_confidence; zero high-risk single-source 30d",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_019",
      "area": "Strategy",
      "question": "Crisis official domain whitelist: Does >=1 official source requirement gate risk_score >0.5 decisions?",
      "why_it_matters": "C11 Red; Q_082 dual-gate; unverified sources cause false pauses; requires authoritative confirmation",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "tests/agents/test_crisis_official_gate.py"],
      "acceptance_signal": "Test dual_gate_risk_cap passes; config official_domains enforced; metric verified_sources",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_020",
      "area": "Compliance",
      "question": "Age gate enforcement: Does JWT age claim <18 trigger 403 at API gateway before reaching application?",
      "why_it_matters": "C12 Red; Q_051/Q_085 CRITICAL; COPPA minor access violation; defense-in-depth required",
      "evidence_anchor": ["middleware/compliance_guard.py", "tests/middleware/test_age_gate.py"],
      "acceptance_signal": "Test age_under_18_403_gateway passes; JWT validated; metric minor_access_blocked",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_021",
      "area": "Compliance",
      "question": "Japan promo label enforcement: Does regex validation block Japan promo submissions lacking Promo/åºå label?",
      "why_it_matters": "C12 Red; Q_052/Q_084 CRITICAL; Japan law requires disclosure; CI blocks unlabeled",
      "evidence_anchor": ["agents/compliance_agent.py", "tests/agents/test_compliance_promo_label_japan.py"],
      "acceptance_signal": "Test japan_promo_label_required passes; regex validates; metric violations=0; CI blocks",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_022",
      "area": "Execution",
      "question": "Budget shift limit: Is weekly budget reallocation capped at Â±25% per channel to prevent drastic swings?",
      "why_it_matters": "C13 Red; Q_053 CRITICAL; >25% shift causes performance variance; requires approval",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_shift_limit.py"],
      "acceptance_signal": "Test budget_shift_25pct_cap passes; >25% requires approval; metric shift_violations=0",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_023",
      "area": "Execution",
      "question": "Allocation ID determinism: Is allocation_id sha256(canonical_json) to ensure same inputs produce same ID?",
      "why_it_matters": "C13 Red; Q_087 CRITICAL; UUID breaks idempotency; retry creates duplicate allocations",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_allocation_id_hash.py"],
      "acceptance_signal": "Test allocation_id_hash_deterministic passes; sha256(canonical); same inputs=same ID",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_024",
      "area": "Execution",
      "question": "Pacing overspend halt: Does daily spend exceeding 110% of pacing target auto-pause campaign within 1h?",
      "why_it_matters": "C14 Red; no pacing control; runaway spend violates budget; real-time halt required",
      "evidence_anchor": ["agents/pacing_agent.py", "tests/agents/test_pacing_overspend.py"],
      "acceptance_signal": "Test pacing_110pct_halt passes; campaign paused <1h; metric overspend_pauses",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_025",
      "area": "Execution",
      "question": "Creative fatigue threshold validation: Is fatigue_score >0.7 threshold validated against historical CTR decay?",
      "why_it_matters": "C15 Red; arbitrary threshold causes premature rotation; need data-driven calibration",
      "evidence_anchor": ["agents/creative_rotation_agent.py", "tests/agents/test_creative_fatigue_threshold.py"],
      "acceptance_signal": "Test fatigue_threshold_validated passes; ROC curve confirms 0.7 optimal; backtest passes",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_026",
      "area": "Execution",
      "question": "Playbook approval timeout: Does approval request escalate to next level after 24h without response?",
      "why_it_matters": "C16 Red; A_011 MINOR; stale approvals block execution; auto-escalation prevents delays",
      "evidence_anchor": ["agents/approval_agent.py", "tests/agents/test_approval_timeout.py"],
      "acceptance_signal": "Test approval_timeout_24h_escalate passes; metric escalations; no >24h pending approvals",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_027",
      "area": "Execution",
      "question": "Playbook dry-run mode: Can playbooks execute in dry-run with no external API calls to validate logic?",
      "why_it_matters": "C16 Red; no dry-run; testing on live campaigns risks revenue; safe testing required",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "tests/agents/test_playbook_dryrun.py"],
      "acceptance_signal": "Test playbook_dryrun_no_api_calls passes; metric dry_runs; zero live API calls in dry-run",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_028",
      "area": "Execution",
      "question": "Activation kill-switch latency: Does KILL_SWITCH_ENABLED=false halt all API pushes within 5s?",
      "why_it_matters": "C17 Red; Q_030 CRITICAL; slow kill-switch allows bad activations; <5s halt required",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_killswitch.py"],
      "acceptance_signal": "Test killswitch_halt_5s passes; all pending pushes cancelled <5s; metric halt_latency",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_029",
      "area": "Execution",
      "question": "Bid update idempotency: Is (campaign_id, bid_value, timestamp) unique to prevent retry bid thrashing?",
      "why_it_matters": "C17 Red; Q_031 CRITICAL; duplicate bid updates cause platform rate limits; idempotent required",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_bid_idempotency.py"],
      "acceptance_signal": "Test bid_dedup_idempotent passes; DB unique constraint; metric duplicate_bids_rejected",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_030",
      "area": "Execution",
      "question": "Activation request_id format: Does request_id follow YYYYMMDD_HHMMSS_UUID4 for uniqueness and debuggability?",
      "why_it_matters": "C17 Red; Q_094 P1; UUID-only lacks timestamp; debug harder; standardized format aids tracing",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_request_id_format.py"],
      "acceptance_signal": "Test request_id_uuid_v4_timestamp passes; format validated; zero collisions 30d",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_031",
      "area": "Governance",
      "question": "Policy rule versioning: Are policy rule changes tracked with version_id and effective_from timestamp?",
      "why_it_matters": "C18 Red; no versioning; policy rollback impossible; audit trail incomplete",
      "evidence_anchor": ["agents/policy_agent.py", "tests/agents/test_policy_versioning.py"],
      "acceptance_signal": "Test policy_version_tracked passes; migrations track version_id; rollback tested",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_032",
      "area": "Observability",
      "question": "Metric cardinality limits: Are high-cardinality labels (user_id, request_id) blocked from Prometheus metrics?",
      "why_it_matters": "C19 Red; unbounded cardinality causes Prometheus OOM; monitoring fails",
      "evidence_anchor": ["agents/monitoring_agent.py", "tests/agents/test_metric_cardinality.py"],
      "acceptance_signal": "Test metric_cardinality_blocked passes; whitelist enforced; metric label_violations",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_033",
      "area": "Observability",
      "question": "P0 alert latency SLO: Do P0 alerts reach PagerDuty within 2min of breach detection?",
      "why_it_matters": "C19/Monitoring_Alerting Red; Q_098 CRITICAL; delayed alerts extend MTTR; <2min SLO required",
      "evidence_anchor": ["agents/monitoring_agent.py", "tests/agents/test_monitoring_p0_alert_latency.py"],
      "acceptance_signal": "Test p0_alert_within_2min passes; PagerDuty API <2min; metric p0_latency <120s",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_034",
      "area": "Observability",
      "question": "Trace sampling strategy: Is tail-based sampling configured to retain 100% of error traces and 1% of success?",
      "why_it_matters": "Infra_Observability Red; head-sampling loses errors; tail-based ensures debug coverage",
      "evidence_anchor": ["infrastructure/otel.py", "tests/infra/test_otel_tail_sampling.py"],
      "acceptance_signal": "Test tail_sampling_100pct_errors passes; OTEL config validated; metric trace_retention",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_035",
      "area": "Observability",
      "question": "Distributed trace context propagation: Does trace_id propagate across async tasks (Prefect/Celery)?",
      "why_it_matters": "Infra_Observability Red; Q_105 done; verify async context continuity for E2E traces",
      "evidence_anchor": ["infrastructure/otel.py", "tests/infra/test_otel_async_context.py"],
      "acceptance_signal": "Test trace_async_propagates passes; Prefect/Celery carry trace_id; metric continuity >=0.99",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_036",
      "area": "RBAC",
      "question": "JWT role enum validation: Does Pydantic RoleEnum prevent typo escalation (e.g., 'admn' bypassing checks)?",
      "why_it_matters": "Infra_Auth Red; Q_107 done; verify enum enforcement prevents privilege escalation via typo",
      "evidence_anchor": ["middleware/auth.py", "schemas/jwt_claims.py", "tests/middleware/test_jwt_role_enum.py"],
      "acceptance_signal": "Test invalid_role_rejected passes; Pydantic RoleEnum; metric invalid_attempts=0",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_037",
      "area": "RBAC",
      "question": "PII mapping access audit: Is every pii_mapping query logged with user, timestamp, reason for 7yr retention?",
      "why_it_matters": "Infra_Auth Red; Q_109 CRITICAL; GDPR requires PII access audit; 7yr retention mandatory",
      "evidence_anchor": ["core/rbac.py", "core/audit.py", "tests/core/test_pii_access_audit.py"],
      "acceptance_signal": "Test pii_access_logged passes; audit_log.pii_access_event; 7yr retention enforced",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_038",
      "area": "RBAC",
      "question": "Service-to-service auth: Do internal agents use mTLS or signed JWTs for inter-service authentication?",
      "why_it_matters": "Infra_Auth Red; no S2S auth; any process can call internal APIs; lateral movement risk",
      "evidence_anchor": ["middleware/auth.py", "infrastructure/mtls.py", "tests/middleware/test_s2s_auth.py"],
      "acceptance_signal": "Test s2s_mtls_or_jwt passes; mTLS or signed JWT enforced; metric unauthorized_s2s=0",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_039",
      "area": "Secrets",
      "question": "Secret Manager retry exponential backoff: Does fetch retry 3x with exponential backoff (max 5s) on transient failures?",
      "why_it_matters": "DataOps_Secrets Red; Q_110 P1; no retry causes boot failures on transient GCP issues",
      "evidence_anchor": ["core/security.py", "tests/core/test_secret_manager_retry.py"],
      "acceptance_signal": "Test secret_retry_3x passes; tenacity backoff max 5s; metric fetch_failures",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_040",
      "area": "Secrets",
      "question": "Pre-commit secret detection: Does detect-secrets hook block commits containing SECRET_/API_KEY patterns?",
      "why_it_matters": "DataOps_Secrets Red; Q_111 done; verify pre-commit prevents secrets in git history",
      "evidence_anchor": [".pre-commit-config.yaml", "tests/infra/test_precommit_secret_detection.py"],
      "acceptance_signal": "Test precommit_blocks_secrets passes; detect-secrets baseline; metric blocked_at_commit",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_041",
      "area": "Secrets",
      "question": "Secret rotation notification: Does Secret Manager notify ops team 30d before secret expiration?",
      "why_it_matters": "DataOps_Secrets Red; expired secrets cause outages; proactive rotation prevents downtime",
      "evidence_anchor": ["core/security.py", "agents/monitoring_agent.py", "tests/core/test_secret_expiry_alert.py"],
      "acceptance_signal": "Test secret_expiry_alert_30d passes; metric days_to_expiry; alert sent <30d",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_042",
      "area": "Infra",
      "question": "Circuit breaker opening: Does circuit open after 3 consecutive failures to prevent cascading Meta API failures?",
      "why_it_matters": "Infra_ExternalAPIs Red; Q_055 CRITICAL; cascading failures amplify downtime; circuit halt <5s",
      "evidence_anchor": ["infrastructure/circuit_breaker.py", "tests/infra/test_circuit_breaker.py"],
      "acceptance_signal": "Test circuit_opens_after_3_fails passes; metric circuit_breaker_opened; API halt <5s",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_043",
      "area": "Infra",
      "question": "Rate limiter burst handling: Does 101st request in 1min get 429 without affecting P99 latency?",
      "why_it_matters": "Infra_ExternalAPIs Red; Q_056 CRITICAL; burst violates 100 req/min; rate limit enforcement required",
      "evidence_anchor": ["infrastructure/rate_limiter.py", "tests/infra/test_rate_limiter.py"],
      "acceptance_signal": "Test rate_limit_101st_429 passes; metric rate_limit_exceeded; P99 latency unaffected",
      "urgency": "P0",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_044",
      "area": "Infra",
      "question": "Connection pool sizing: Is external API connection pool sized to max_concurrent * (timeout_s / avg_req_s) + buffer?",
      "why_it_matters": "Infra_ExternalAPIs Red; undersized pool causes connection exhaustion; oversized wastes resources",
      "evidence_anchor": ["infrastructure/http_client.py", "tests/infra/test_connection_pool_sizing.py"],
      "acceptance_signal": "Test pool_size_calculated passes; formula validated; metric pool_exhaustion=0",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_045",
      "area": "Infra",
      "question": "Container resource limits: Are CPU/memory limits set with request=80% of limit to prevent OOMKilled?",
      "why_it_matters": "Infra general; no resource limits causes node evictions; request/limit ratio critical",
      "evidence_anchor": ["infrastructure/k8s_deployments.yaml", "tests/infra/test_k8s_resource_limits.py"],
      "acceptance_signal": "Test k8s_resource_limits_80pct passes; request=0.8*limit; metric oom_kills=0",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_046",
      "area": "Compliance",
      "question": "Audit log immutability: Does DB trigger block UPDATE/DELETE on audit_log table for SOX compliance?",
      "why_it_matters": "C20/Compliance_AuditLog Red; Q_100/A_015 CRITICAL; mutable logs violate SOX; DB enforced",
      "evidence_anchor": ["core/audit.py", "migrations/audit_log_immutable_trigger.sql", "tests/core/test_audit_immutability.py"],
      "acceptance_signal": "Test audit_no_update passes; DB trigger blocks UPDATE/DELETE; metric mutation_attempts=0",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_047",
      "area": "Compliance",
      "question": "Audit log 7yr retention: Is partition expiration disabled and archival to cold storage configured for 7yr?",
      "why_it_matters": "Compliance_AuditLog Red; A_015 MAJOR; <7yr retention violates SOX/GDPR; archival required",
      "evidence_anchor": ["core/audit.py", "infrastructure/archival.py", "tests/core/test_audit_retention_7yr.py"],
      "acceptance_signal": "Test audit_retention_7yr passes; BigQuery partition expiration=never; cold storage archival",
      "urgency": "P1",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_048",
      "area": "Data",
      "question": "Multi-currency revenue normalization: Are all revenue_jpy conversions using historical FX rates at order_date?",
      "why_it_matters": "DataOps_Revenue Red; A_016 gap; spot rate causes revenue volatility; historical rates required",
      "evidence_anchor": ["core/revenue.py", "tests/core/test_revenue_fx_normalization.py"],
      "acceptance_signal": "Test fx_rate_historical passes; order_date rate used; metric fx_mismatch=0",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_049",
      "area": "Data",
      "question": "Schema version tagging: Does every schema change get tagged with version_id in migrations?",
      "why_it_matters": "DataOps_Validation Red; no versioning; rollback impossible; schema drift untrackable",
      "evidence_anchor": ["migrations/", "tests/infra/test_schema_versioning.py"],
      "acceptance_signal": "Test schema_version_tagged passes; alembic/migration script tagged; rollback tested",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_050",
      "area": "CI/CD",
      "question": "Deploy gate 100% green tests: Does GitHub Actions deployment block if any test fails?",
      "why_it_matters": "CI_CD Red; Q_113 CRITICAL; flaky tests to prod cause regressions; 100% pass required",
      "evidence_anchor": [".github/workflows/deploy.yml", "tests/infra/test_deploy_gate.py"],
      "acceptance_signal": "Test deploy_requires_100pct passes; workflow gate enforced; metric failed_deploys=0",
      "urgency": "P0",
      "owner_hint": "Infra"
    }
  ]
}
