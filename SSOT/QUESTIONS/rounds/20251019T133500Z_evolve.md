{
  "questions": [
    {
      "id": "Q_551",
      "area": "Data",
      "question": "What is the exact deduplication window for ad spend ingestion to prevent double-counting on retries?",
      "why_it_matters": "Q_503 capsule item requires dedup_ttl=8d; coverage shows C_AdPlatform partial impl but no dedup window config",
      "evidence_anchor": ["agents/ad_platform_agent.py", "config/ingestion.yml"],
      "acceptance_signal": "Config has dedup_ttl=8d and test confirms retry after 7d adds record, retry at 9d rejects",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_552",
      "area": "Features",
      "question": "How do we guarantee feature cache staleness p95≤60s when Redis has network partitions?",
      "why_it_matters": "Q_501 capsule item requires p95≤60s metric; no failover path documented in feature_store",
      "evidence_anchor": ["core/feature_store.py", "config/redis.yml"],
      "acceptance_signal": "Metric feature_cache_staleness_p95_seconds exists and p95≤60 over 7d with simulated partition",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_553",
      "area": "Features",
      "question": "Does feature write use 2PC to rollback cache on DB failure, or is cache-write fire-and-forget?",
      "why_it_matters": "Q_448 capsule requires 2PC atomic cache rollback; current impl unclear if cache/DB sync guaranteed",
      "evidence_anchor": ["core/feature_store.py", "tests/core/test_feature_store.py"],
      "acceptance_signal": "Test confirms DB write fails → cache entry removed; trace shows 2PC span with rollback branch",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_554",
      "area": "Strategy",
      "question": "What MMM holdout period ensures unbiased model evaluation without data leakage from recent campaigns?",
      "why_it_matters": "Q_538 capsule requires holdout=4wk; no holdout config in mmm_agent; risk of overfitting",
      "evidence_anchor": ["agents/mmm_agent.py", "tests/agents/test_mmm_agent.py"],
      "acceptance_signal": "Test confirms training uses data t-56d to t-28d, validation uses t-27d to t-1d, no overlap",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_555",
      "area": "Strategy",
      "question": "How do we alert when MMM/MTA attribution divergence exceeds 20% indicating model drift or data quality issue?",
      "why_it_matters": "Q_506 capsule requires divergence>20%→Slack P1; no reconciliation metric or alert exists",
      "evidence_anchor": ["agents/mmm_agent.py", "agents/mta_agent.py", "core/alerting.py"],
      "acceptance_signal": "Metric mta_mmm_divergence_pct exists; test confirms >20% triggers P1 Slack alert within 120s",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_556",
      "area": "Execution",
      "question": "What exponential backoff max delay prevents activation retry storms during platform rate-limiting?",
      "why_it_matters": "Q_539 capsule requires exp backoff max=300s; no backoff config in activation_agent",
      "evidence_anchor": ["agents/activation_agent.py", "config/activation.yml"],
      "acceptance_signal": "Config has retry_backoff_max=300s; test confirms 5 retries reach 300s cap, no further growth",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_557",
      "area": "Execution",
      "question": "Does activation 2PC commit complete within p95≤5s or do slow ad platform APIs cause timeout failures?",
      "why_it_matters": "Q_541 capsule requires p95≤5s; no 2PC latency metric; slow commits risk inconsistent state",
      "evidence_anchor": ["agents/activation_agent.py", "metrics/activation_latency.yml"],
      "acceptance_signal": "Metric activation_2pc_latency_p95_seconds exists and p95≤5s over 7d with real platform calls",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_558",
      "area": "Execution",
      "question": "How does activation timeout rollback ensure 2PC rollback without leaving partial changes on ad platforms?",
      "why_it_matters": "Q_441 capsule requires 2PC rollback on timeout; no rollback compensation logic documented",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_agent.py"],
      "acceptance_signal": "Test confirms timeout after prepare→rollback called→ad platform change reverted or compensated",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_559",
      "area": "Risk",
      "question": "What relative budget cap prevents >250% weekly allocation spikes that could drain reserves?",
      "why_it_matters": "Q_022 capsule requires 10K→35K reject(250%); no relative cap in budget_allocation_agent",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_allocation_agent.py"],
      "acceptance_signal": "Test confirms prior_week=10K, new_alloc=35K→rejected with BudgetCapViolation",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_560",
      "area": "Risk",
      "question": "Does budget allocation hash include server timestamp to prevent client replay attacks submitting stale decisions?",
      "why_it_matters": "Q_415 capsule requires server_timestamp in hash; no timestamp in current hash composition",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_allocation_agent.py"],
      "acceptance_signal": "Test confirms hash includes server_ts; replay with old hash rejected as stale",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_561",
      "area": "Risk",
      "question": "What dual cap (±25% AND <$50K) prevents both relative spikes and absolute overspend on single allocations?",
      "why_it_matters": "Q_416 capsule requires dual cap; current impl only checks relative OR absolute, not both",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "tests/agents/test_budget_allocation_agent.py"],
      "acceptance_signal": "Test confirms 120% shift with $60K→rejected; 20% shift with $60K→rejected",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_562",
      "area": "Risk",
      "question": "How does pacing check asset-level spend_rate to pause individual creatives exceeding budget without pausing entire campaign?",
      "why_it_matters": "Q_417 capsule requires per-asset spend_rate check; current impl only campaign-level",
      "evidence_anchor": ["agents/pacing_agent.py", "tests/agents/test_pacing_agent.py"],
      "acceptance_signal": "Test confirms asset A 120%, asset B 80%→only A paused, B continues",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_563",
      "area": "Risk",
      "question": "What pacing sibling aggregation prevents pausing asset A without checking if siblings B+C combined still exceed budget?",
      "why_it_matters": "Q_438 capsule requires sibling check; pausing A alone may leave B+C overspending",
      "evidence_anchor": ["agents/pacing_agent.py", "tests/agents/test_pacing_agent.py"],
      "acceptance_signal": "Test confirms A paused, B+C aggregate checked, if >110% then B+C also paused",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_564",
      "area": "Risk",
      "question": "What pacing pause latency metric ensures breach_ts-pause_ts p95<3600s for timely overspend prevention?",
      "why_it_matters": "Q_439 capsule requires p95<3600s; no latency metric for pause action",
      "evidence_anchor": ["agents/pacing_agent.py", "metrics/pacing_latency.yml"],
      "acceptance_signal": "Metric pacing_pause_latency_p95_seconds exists and p95<3600 over 7d",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_565",
      "area": "Execution",
      "question": "How does kill-switch queue flush immediately cancel pending activation tasks without waiting for timeout?",
      "why_it_matters": "Q_440 capsule requires stop_flag+cancel; no immediate flush logic in activation queue",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_agent.py"],
      "acceptance_signal": "Test confirms kill_switch set→pending tasks cancelled within 5s, no new tasks accepted",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_566",
      "area": "Execution",
      "question": "Does activation retry include jitter and global rate-limiting to avoid thundering herd on platform recovery?",
      "why_it_matters": "Q_442 capsule requires exp+jitter+rate-limit; no jitter or global limit in current retry",
      "evidence_anchor": ["agents/activation_agent.py", "config/activation.yml"],
      "acceptance_signal": "Config has jitter_ms=100-500; test confirms 100 concurrent retries spread over 30s window",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_567",
      "area": "Execution",
      "question": "What activation mutation hash includes mutation_seq to prevent idempotency collisions on same-day multi-edit?",
      "why_it_matters": "Q_419 capsule requires mutation_seq in hash; current hash only date+campaign_id",
      "evidence_anchor": ["agents/activation_agent.py", "tests/agents/test_activation_agent.py"],
      "acceptance_signal": "Test confirms 2 edits same day→distinct hashes via mutation_seq increment",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_568",
      "area": "Observability",
      "question": "What kill-switch trace latency confirms e2e spans p95<5s from trigger to ACK in distributed activation flow?",
      "why_it_matters": "Q_418 capsule requires trace p95<5s; no trace span for kill-switch path",
      "evidence_anchor": ["agents/activation_agent.py", "config/tracing.yml"],
      "acceptance_signal": "Trace span kill_switch_activation exists; p95 latency <5s over 7d with test triggers",
      "urgency": "P0",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_569",
      "area": "Governance",
      "question": "How does audit S3 fallback guarantee 60s replay window if primary DB write fails during burst traffic?",
      "why_it_matters": "Q_420 capsule requires S3 write+60s replay; no S3 fallback in audit.py",
      "evidence_anchor": ["core/audit.py", "config/audit.yml"],
      "acceptance_signal": "Test confirms DB write fails→S3 write succeeds→60s later replayed to DB from S3",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_570",
      "area": "Governance",
      "question": "What audit S3 window prevents immediate replay during ongoing DB outage causing replay storm?",
      "why_it_matters": "Q_443 capsule requires 60s wait; immediate replay risks amplifying outage",
      "evidence_anchor": ["core/audit.py", "config/audit.yml"],
      "acceptance_signal": "Config has s3_replay_delay_seconds=60; test confirms no replay until 60s elapsed",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_571",
      "area": "Secrets",
      "question": "Does HMAC multi-key versioning store last 4 keys to support gradual rotation without breaking audit verification?",
      "why_it_matters": "Q_421 capsule requires last 4 keys; current impl only 1 key risks verification failure during rotation",
      "evidence_anchor": ["core/audit.py", "config/hmac.yml"],
      "acceptance_signal": "Config has hmac_key_versions=4; test confirms rotation→old records still verify with key_version",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_572",
      "area": "Secrets",
      "question": "What HMAC multi-key versioning ensures key_version field in audit records for backward-compatible verification?",
      "why_it_matters": "Q_444 capsule requires key_version in record; no version field in current audit schema",
      "evidence_anchor": ["core/audit.py", "schemas/audit.schema.json"],
      "acceptance_signal": "Schema has key_version field; test confirms record includes key_version matching rotation timestamp",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_573",
      "area": "Secrets",
      "question": "Does HMAC KMS isolation use separate KMS keys for audit HMAC vs API secrets to limit blast radius?",
      "why_it_matters": "Q_446 capsule requires hmac_kms≠api_kms; current config uses single KMS key for all secrets",
      "evidence_anchor": ["config/kms.yml", "core/secrets.py"],
      "acceptance_signal": "Config has hmac_kms_key_id≠api_kms_key_id; test confirms HMAC uses dedicated KMS",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_574",
      "area": "Observability",
      "question": "What P0 immediate alert path bypasses queue to deliver critical alerts via direct API within p0_delay=0?",
      "why_it_matters": "Q_445 capsule requires direct API p0_delay=0; current alerts use async queue with delay",
      "evidence_anchor": ["core/alerting.py", "config/alert_routing.yml"],
      "acceptance_signal": "Config has p0_direct=true; test confirms P0 alert sent via direct API call, no queue",
      "urgency": "P0",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_575",
      "area": "Observability",
      "question": "What P0 alert latency metric confirms p95<120s from alert generation to delivery acknowledgment?",
      "why_it_matters": "Q_422 capsule requires p95<120s metric; no latency tracking for alert delivery",
      "evidence_anchor": ["core/alerting.py", "metrics/alert_latency.yml"],
      "acceptance_signal": "Metric alert_latency_p95_seconds exists; p95<120s over 7d with test P0 alerts",
      "urgency": "P0",
      "owner_hint": "Observability"
    },
    {
      "id": "Q_576",
      "area": "RBAC",
      "question": "How does RBAC approval TOCTOU prevention re-check permissions at grant time to prevent race conditions?",
      "why_it_matters": "Q_447 capsule requires re-check at grant; no TOCTOU guard in approval_agent",
      "evidence_anchor": ["agents/approval_agent.py", "tests/agents/test_approval_agent.py"],
      "acceptance_signal": "Test confirms approver role revoked between request→grant→grant fails with PermissionDenied",
      "urgency": "P0",
      "owner_hint": "RBAC"
    },
    {
      "id": "Q_577",
      "area": "RBAC",
      "question": "What approval delegation chain limit prevents cascading approvals exceeding 3 hops for audit clarity?",
      "why_it_matters": "Q_516 capsule requires chain≤3; no delegation depth limit in approval logic",
      "evidence_anchor": ["agents/approval_agent.py", "tests/agents/test_approval_agent.py"],
      "acceptance_signal": "Test confirms 4th delegation attempt→rejected with DelegationDepthExceeded",
      "urgency": "P0",
      "owner_hint": "RBAC"
    },
    {
      "id": "Q_578",
      "area": "Secrets",
      "question": "What API key rotation grace period allows 5min overlap to prevent service disruption during rotation?",
      "why_it_matters": "Q_518 capsule requires 5min grace; no overlap window in current key rotation",
      "evidence_anchor": ["core/secrets.py", "tests/core/test_secrets.py"],
      "acceptance_signal": "Test confirms old key valid for 5min after new key activated; requests succeed with both",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_579",
      "area": "Secrets",
      "question": "Does KMS failure mode fail_closed to reject all secret requests when KMS unavailable instead of unsafe fallback?",
      "why_it_matters": "Q_519 capsule requires fail_closed; unclear if current impl falls back to cache on KMS failure",
      "evidence_anchor": ["core/secrets.py", "config/kms.yml"],
      "acceptance_signal": "Config has kms_failure_mode=fail_closed; test confirms KMS down→secret requests rejected",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_580",
      "area": "CI/CD",
      "question": "How does contract backward-compat CI check fail the build if breaking schema changes detected?",
      "why_it_matters": "Q_522 capsule requires breaking→fail; no contract diff in CI pipeline",
      "evidence_anchor": ["tests/contracts/", ".github/workflows/ci.yml"],
      "acceptance_signal": "CI job contract-check fails if schema field removed; test with breaking change→build red",
      "urgency": "P0",
      "owner_hint": "CI/CD"
    },
    {
      "id": "Q_581",
      "area": "Compliance",
      "question": "What GDPR cascade deletion ensures all user data deleted within <30d including backups and logs?",
      "why_it_matters": "Q_527 capsule requires cascade <30d; no cascade policy or audit trail exists",
      "evidence_anchor": ["core/gdpr.py", "tests/core/test_gdpr.py"],
      "acceptance_signal": "Test confirms delete request→all tables+S3+logs purged within 30d; audit record confirms",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_582",
      "area": "Compliance",
      "question": "Does cross-border data transfer rejection ensure EEA-only data residency for GDPR compliance?",
      "why_it_matters": "Q_529 capsule requires EEA only; no region validation in data export flows",
      "evidence_anchor": ["core/gdpr.py", "config/regions.yml"],
      "acceptance_signal": "Config has allowed_regions=[EEA]; test confirms export to US→rejected with RegionViolation",
      "urgency": "P0",
      "owner_hint": "Compliance"
    },
    {
      "id": "Q_583",
      "area": "Data",
      "question": "What revenue variance metric alerts when e-commerce revenue differs from platform revenue by >1%?",
      "why_it_matters": "Q_530 capsule requires variance<1%; no reconciliation metric exists",
      "evidence_anchor": ["agents/ecommerce_agent.py", "metrics/revenue_variance.yml"],
      "acceptance_signal": "Metric revenue_variance_pct exists; test confirms >1% diff→P1 alert within 300s",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_584",
      "area": "Strategy",
      "question": "How does playbook DAG cycle detection prevent circular dependencies causing infinite loop execution?",
      "why_it_matters": "Q_534 capsule requires circular→error; no cycle detection in playbook_orchestrator",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "tests/agents/test_playbook_orchestrator.py"],
      "acceptance_signal": "Test confirms playbook A→B→A dependency→rejected with CyclicDependencyError",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_585",
      "area": "Risk",
      "question": "What policy conflict resolution uses most_restrictive rule when multiple policies apply to same content?",
      "why_it_matters": "Q_537 capsule requires most_restrictive; no conflict resolution in policy_agent",
      "evidence_anchor": ["agents/policy_agent.py", "tests/agents/test_policy_agent.py"],
      "acceptance_signal": "Test confirms policy A allows, policy B blocks→content blocked (most restrictive wins)",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_586",
      "area": "Governance",
      "question": "What audit 7yr retention ensures immutable logs stored for regulatory compliance without purge?",
      "why_it_matters": "Q_543 capsule requires 7yr retention; current audit logs have 90d TTL only",
      "evidence_anchor": ["core/audit.py", "config/audit.yml"],
      "acceptance_signal": "Config has retention_years=7; test confirms records >90d still accessible from archive",
      "urgency": "P0",
      "owner_hint": "Governance"
    },
    {
      "id": "Q_587",
      "area": "Secrets",
      "question": "Does log secret redaction automatically mask api_key, password, token fields to prevent credential leakage?",
      "why_it_matters": "Q_545 capsule requires redact api_key; no auto-redaction in logging middleware",
      "evidence_anchor": ["core/logging.py", "tests/core/test_logging.py"],
      "acceptance_signal": "Test confirms log with api_key=abc123→output shows api_key=***REDACTED***",
      "urgency": "P0",
      "owner_hint": "Secrets"
    },
    {
      "id": "Q_588",
      "area": "CI/CD",
      "question": "What canary auto-rollback triggers rollback within 2min if error rate exceeds 5% during deployment?",
      "why_it_matters": "Q_547 capsule requires error>5%→rollback<2min; no auto-rollback in deploy workflow",
      "evidence_anchor": [".github/workflows/deploy.yml", "config/canary.yml"],
      "acceptance_signal": "Config has canary_error_threshold=0.05; test confirms 6% error→rollback triggered<120s",
      "urgency": "P0",
      "owner_hint": "CI/CD"
    },
    {
      "id": "Q_589",
      "area": "Data",
      "question": "What journey stitch precision metric confirms identity resolution achieves ≥85% accuracy on cross-device paths?",
      "why_it_matters": "Q_550 capsule requires precision≥85%; no accuracy metric for identity resolution",
      "evidence_anchor": ["agents/identity_resolution_agent.py", "metrics/identity_precision.yml"],
      "acceptance_signal": "Metric identity_stitch_precision exists; test with ground-truth→precision≥0.85",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_590",
      "area": "Risk",
      "question": "How does crisis tier governance ensure quarterly audits of official_domains.yml for tier-1 source accuracy?",
      "why_it_matters": "Q_411 capsule requires quarterly audit; no audit schedule or ownership defined",
      "evidence_anchor": ["config/official_domains.yml", "docs/governance/crisis_domains.md"],
      "acceptance_signal": "Doc specifies quarterly review by Risk team; test confirms last_audit_date within 90d",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_591",
      "area": "Risk",
      "question": "What crisis baseline normalize applies day-of-week multipliers to account for organic traffic patterns?",
      "why_it_matters": "Q_412 capsule requires day-of-week multipliers; no normalization in crisis_detection_agent",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "config/crisis_baseline.yml"],
      "acceptance_signal": "Config has day_of_week_factors=[1.0,0.9,0.9,0.9,0.9,1.1,1.2]; test confirms normalized correctly",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_592",
      "area": "Risk",
      "question": "What crisis fallback tier uses tier2+5σ when tier-1 sources unavailable to prevent false negatives?",
      "why_it_matters": "Q_429 capsule requires tier2+5σ fallback; no fallback logic in crisis detection",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "config/crisis_tiers.yml"],
      "acceptance_signal": "Config has fallback_tier=tier2, fallback_threshold=5sigma; test confirms tier1 down→tier2 used",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_593",
      "area": "Risk",
      "question": "Does crisis baseline outlier exclusion use Tukey fences to remove anomalies before computing baseline?",
      "why_it_matters": "Q_430 capsule requires Tukey fences; no outlier removal in baseline calculation",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "tests/agents/test_crisis_detection_agent.py"],
      "acceptance_signal": "Test confirms outliers >Q3+1.5*IQR excluded; baseline computed on clean data",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_594",
      "area": "Risk",
      "question": "What crisis min sample threshold switches to fixed threshold when n<100 to avoid statistical instability?",
      "why_it_matters": "Q_431 capsule requires n<100→fixed threshold; no sample size check in crisis logic",
      "evidence_anchor": ["agents/crisis_detection_agent.py", "config/crisis_baseline.yml"],
      "acceptance_signal": "Config has min_sample=100, fixed_threshold=50; test confirms n=80→fixed threshold used",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_595",
      "area": "Risk",
      "question": "How does budget retry jitter add 100-500ms random delay plus exp backoff to prevent synchronized retries?",
      "why_it_matters": "Q_436 capsule requires jitter+backoff; no jitter in current retry logic",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "config/retry.yml"],
      "acceptance_signal": "Config has jitter_ms=[100,500]; test confirms retries spread over time with jitter variance",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_596",
      "area": "Risk",
      "question": "What budget breach audit tracks breach_pct and repeat offenders in dashboard for governance review?",
      "why_it_matters": "Q_437 capsule requires breach audit; no breach tracking or dashboard exists",
      "evidence_anchor": ["agents/budget_allocation_agent.py", "dashboards/budget_breach.json"],
      "acceptance_signal": "Dashboard shows breach_pct by channel; test confirms 3 breaches in 7d→repeat_offender flag",
      "urgency": "P0",
      "owner_hint": "Risk"
    },
    {
      "id": "Q_597",
      "area": "Playbook",
      "question": "What playbook timeout action rejects the decision when approval timeout expires instead of auto-approving?",
      "why_it_matters": "Q_511 capsule requires timeout_action=reject; unclear if timeout defaults to approve or reject",
      "evidence_anchor": ["agents/playbook_orchestrator.py", "config/playbook.yml"],
      "acceptance_signal": "Config has timeout_action=reject; test confirms 24h timeout→decision rejected, not executed",
      "urgency": "P0",
      "owner_hint": "Strategy"
    },
    {
      "id": "Q_598",
      "area": "Execution",
      "question": "How does creative rotation race prevention use optimistic lock to avoid double-rotation of same asset?",
      "why_it_matters": "Q_510 capsule requires optimistic lock; no version check in creative_rotation_agent",
      "evidence_anchor": ["agents/creative_rotation_agent.py", "tests/agents/test_creative_rotation_agent.py"],
      "acceptance_signal": "Test confirms concurrent rotation→one succeeds, other fails with VersionConflict",
      "urgency": "P0",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_599",
      "area": "Features",
      "question": "What feature cache TTL≤60s prevents stale feature reads causing budget allocation errors?",
      "why_it_matters": "Q_449 capsule requires TTL≤60s; no explicit TTL config in feature_store",
      "evidence_anchor": ["core/feature_store.py", "config/redis.yml"],
      "acceptance_signal": "Config has feature_cache_ttl=60; test confirms cache entry expires after 60s",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_600",
      "area": "Data",
      "question": "What is the exact mechanism for journey stitch probabilistic matching to exceed 85% precision on cross-device attribution?",
      "why_it_matters": "Coverage shows C01 Yellow with tests but no precision validation; Q_550 requires ≥85% precision metric",
      "evidence_anchor": ["agents/identity_resolution_agent.py", "tests/agents/test_identity_resolution_agent.py"],
      "acceptance_signal": "Test uses labeled ground-truth dataset; precision metric ≥0.85 on cross-device paths",
      "urgency": "P0",
      "owner_hint": "DataOps"
    }
  ]
}
