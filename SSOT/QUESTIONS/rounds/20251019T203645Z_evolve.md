{
  "questions": [
    {
      "id": "Q_051",
      "area": "Data",
      "question": "Does ConversionPath schema validate privacy-safe aggregation before MTA calculations?",
      "why_it_matters": "A_006 requires contract-first MTA schemas; missing validation risks PII leakage in attribution paths",
      "evidence_anchor": ["src/agents/mta/schemas.py", "src/agents/mta/mta_agent.py", "tests/test_mta_contracts.py"],
      "acceptance_signal": "Pydantic ConversionPath schema exists with privacy checks; unit tests enforce no individual tracking",
      "urgency": "P0",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_052",
      "area": "Data",
      "question": "Are Markov transition matrices validated for probability sum == 1.0 in MTA?",
      "why_it_matters": "A_006 contract drift; invalid transition probabilities corrupt attribution weights",
      "evidence_anchor": ["src/agents/mta/mta_agent.py", "tests/test_mta_contracts.py"],
      "acceptance_signal": "Unit test verifies sum(transitions[state].values()) == 1.0 for all states",
      "urgency": "P0",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_053",
      "area": "Features",
      "question": "Does FeatureStore implement online/offline parity validation on a schedule?",
      "why_it_matters": "A_008 observability gap; offline training features diverging from online serving breaks model accuracy",
      "evidence_anchor": ["src/feature_store/parity_validator.py", "src/feature_store/metrics.py", "tests/test_feature_parity.py"],
      "acceptance_signal": "Scheduled job runs parity validation; alerts fire when offline != online features",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_054",
      "area": "Features",
      "question": "Is feature store online serving latency tracked with p99 SLA enforcement?",
      "why_it_matters": "A_008 requires <50ms p99 latency; missing SLA tracking causes silent performance degradation",
      "evidence_anchor": ["src/feature_store/metrics.py", "prometheus/feature_store.yml"],
      "acceptance_signal": "Prometheus histogram tracks feature_store_latency_ms with p99 alert at 50ms threshold",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_055",
      "area": "Observability",
      "question": "Do all LLM calls emit structured logs with prompt_hash and source_ids?",
      "why_it_matters": "LLM guardrails active (Q_004 done) but observability incomplete; missing audit trail for RAG-only verification",
      "evidence_anchor": ["src/agents/llm/llm_guardrails.py", "db/schema/llm_calls.sql", "tests/test_llm_observability.py"],
      "acceptance_signal": "Every LLM API call inserts llm_calls table row; logs include prompt_hash and source_ids array",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_056",
      "area": "Observability",
      "question": "Is Prometheus scraping endpoint /system/metrics for all agent latency histograms?",
      "why_it_matters": "Coverage shows no Observability artifacts; missing metrics prevent SLO tracking and alerting",
      "evidence_anchor": ["src/api/metrics.py", "prometheus/scrape_config.yml", "tests/test_prometheus_endpoint.py"],
      "acceptance_signal": "GET /system/metrics returns Prometheus format; mbi_agent_latency_seconds histogram exists",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_057",
      "area": "Risk",
      "question": "Does Budget Allocation Agent enforce hard ROAS constraints before activation?",
      "why_it_matters": "C08_BudgetAllocation is Red; optimizer may violate target ROAS if constraints not enforced",
      "evidence_anchor": ["src/agents/budget/budget_allocation_agent.py", "tests/test_budget_constraints.py"],
      "acceptance_signal": "Unit test verifies allocation rejected if any channel ROAS < min_roas threshold",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_058",
      "area": "Risk",
      "question": "Are playbook executions gated by max_shift_pct_per_week guardrail in config?",
      "why_it_matters": "C09_PlaybookOrch is Red; ungated budget shifts risk over-allocating to volatile channels",
      "evidence_anchor": ["src/agents/playbook/playbook_orchestrator.py", "config/guardrails.yml", "tests/test_playbook_guardrails.py"],
      "acceptance_signal": "Playbook execution blocked when proposed shift > guardrails.max_shift_pct; logged in audit_log",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_059",
      "area": "Execution",
      "question": "Does Activation Agent implement retry with exponential backoff for ad platform API failures?",
      "why_it_matters": "C09_PlaybookOrch needs resilient activation; missing retry causes playbook failures on transient errors",
      "evidence_anchor": ["src/agents/activation/activation_agent.py", "tests/test_activation_retry.py"],
      "acceptance_signal": "Unit test verifies 3 retries with exponential backoff; final failure logged in audit_log",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_060",
      "area": "Execution",
      "question": "Are budget allocation decisions logged with full input_hash and output_hash for audit?",
      "why_it_matters": "Coverage shows no audit_log implementation; missing trail prevents compliance verification",
      "evidence_anchor": ["db/schema/audit_log.sql", "src/agents/budget/budget_allocation_agent.py", "tests/test_audit_logging.py"],
      "acceptance_signal": "Every allocation decision inserts audit_log row with decision JSON, hashes, approved_by",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_061",
      "area": "Data",
      "question": "Does Analytics Agent (GA4) implement event deduplication by session_id + event_id?",
      "why_it_matters": "C07_DataIngestion idempotency partially resolved (A_001 done for ads); GA4 events may still duplicate",
      "evidence_anchor": ["src/agents/ingestion/analytics_agent.py", "tests/test_analytics_idempotency.py"],
      "acceptance_signal": "Unit test verifies duplicate event insertions result in single row; unique constraint on (session_id, event_id, timestamp)",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_062",
      "area": "Data",
      "question": "Is E-commerce Agent (Shopify) webhook receiver validating HMAC signatures?",
      "why_it_matters": "A_007 done for generic webhooks; Shopify-specific HMAC validation may be missing",
      "evidence_anchor": ["src/agents/ingestion/ecommerce_agent.py", "tests/test_shopify_webhook_security.py"],
      "acceptance_signal": "Unit test verifies webhook rejected if HMAC invalid; uses Shopify shared secret from KMS",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_063",
      "area": "Secrets",
      "question": "Are all Shopify/Meta/Google API credentials retrieved from Secret Manager with TTL checks?",
      "why_it_matters": "A_005 done for generic secrets; per-platform credential rotation may not be enforced",
      "evidence_anchor": ["src/config/secrets.py", "terraform/secrets.tf", "tests/test_platform_secrets.py"],
      "acceptance_signal": "secrets.get_api_key(platform) retrieves from GCP Secret Manager; logs rotation age; fails if > 90 days",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_064",
      "area": "Compliance",
      "question": "Does GDPR TTL enforcement actually delete hashed user_keys after 90 days?",
      "why_it_matters": "Q_002 done with TTL config; execution of deletion may not be implemented",
      "evidence_anchor": ["src/agents/identity/identity_resolution_agent.py", "db/jobs/gdpr_cleanup.sql", "tests/test_gdpr_cleanup.py"],
      "acceptance_signal": "Scheduled job deletes dim_user rows where valid_to < now() - 90 days; test verifies cleanup",
      "urgency": "P0",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_065",
      "area": "Compliance",
      "question": "Are promotional content compliance checks (Promo/広告 labeling) enforced before creative activation?",
      "why_it_matters": "LLM guardrails active (Q_004) but policy agent enforcement may be missing for non-LLM content",
      "evidence_anchor": ["src/agents/compliance/policy_agent.py", "tests/test_promo_labeling.py"],
      "acceptance_signal": "Creative activation blocked if text lacks Promo/広告 label; logged in audit_log",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_066",
      "area": "Strategy",
      "question": "Does Creative Intelligence Agent handle multi-modal embeddings (vision + text)?",
      "why_it_matters": "C04_CreativeIntel is Red; queue item Q_018 deferred; missing vision embeddings limits asset analysis",
      "evidence_anchor": ["src/agents/creative/creative_intelligence_agent.py", "tests/test_creative_multimodal.py"],
      "acceptance_signal": "Agent uses CLIP or similar for image/video; combines with text embeddings; test validates motif extraction",
      "urgency": "P1",
      "owner_hint": "ML"
    },
    {
      "id": "Q_067",
      "area": "Strategy",
      "question": "Are creative fatigue scores calculated with exponential weighted moving average (EWMA)?",
      "why_it_matters": "C04_CreativeIntel basic fatigue detection may use simple linear regression; EWMA more robust to noise",
      "evidence_anchor": ["src/agents/creative/creative_intelligence_agent.py", "tests/test_fatigue_calculation.py"],
      "acceptance_signal": "Fatigue score uses EWMA with alpha=0.3; test validates decay behavior on mock time series",
      "urgency": "P2",
      "owner_hint": "ML"
    },
    {
      "id": "Q_068",
      "area": "Features",
      "question": "Does Feature Engineering Agent compute time-windowed aggregations with correct timezone handling?",
      "why_it_matters": "User location is Yokohama JP; UTC/JST mismatch in window boundaries corrupts daily/weekly features",
      "evidence_anchor": ["src/agents/feature/feature_engineering_agent.py", "tests/test_timezone_windows.py"],
      "acceptance_signal": "All window calculations use pytz.timezone('Asia/Tokyo'); test verifies 24-hour window aligns with JST day",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_069",
      "area": "Latency",
      "question": "Is Redis cache configured with eviction policy allkeys-lru for LLM response cache?",
      "why_it_matters": "FinOps caching for LLM calls; wrong eviction policy causes cache thrashing and cost spikes",
      "evidence_anchor": ["terraform/redis.tf", "src/agents/llm/llm_guardrails.py", "tests/test_llm_cache_eviction.py"],
      "acceptance_signal": "Redis config has maxmemory-policy=allkeys-lru; test validates LRU eviction under memory pressure",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_070",
      "area": "Latency",
      "question": "Does BigQuery export to feature store use streaming inserts or batch with optimal partition?",
      "why_it_matters": "Feature store requires <6 hour lag; wrong insert method causes data freshness SLA violations",
      "evidence_anchor": ["src/agents/feature/feature_store_sync.py", "tests/test_bq_streaming.py"],
      "acceptance_signal": "Uses BigQuery streaming API or batches ≤ 1000 rows; partitioned by dt; test validates lag < 6h",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_071",
      "area": "Backtest",
      "question": "Is MMM model validation using true out-of-sample holdout (not cross-validation)?",
      "why_it_matters": "Q_003 implemented MAPE tracking; cross-validation on time series leaks future info and inflates accuracy",
      "evidence_anchor": ["src/agents/mmm/mmm_agent.py", "src/agents/mmm/model_validator.py", "tests/agents/mmm/test_mmm_validation.py"],
      "acceptance_signal": "Holdout set is chronologically last 20% of data; no shuffle; test verifies temporal split",
      "urgency": "P0",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_072",
      "area": "Backtest",
      "question": "Does MTA attribution reconcile with MMM estimates within 15% margin?",
      "why_it_matters": "MTA and MMM both allocate revenue; large divergence indicates model/data quality issues",
      "evidence_anchor": ["src/agents/mta/mta_agent.py", "src/agents/mmm/mmm_agent.py", "tests/test_attribution_reconciliation.py"],
      "acceptance_signal": "Test compares MTA weights vs MMM incremental contribution; fails if any channel differs > 15%",
      "urgency": "P1",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_073",
      "area": "CI/CD",
      "question": "Are contract schemas (Pydantic) tested in CI before merging to main?",
      "why_it_matters": "Contract-first principle; schema changes without tests can break multiple agents silently",
      "evidence_anchor": [".github/workflows/ci.yml", "tests/schemas/", "pyproject.toml"],
      "acceptance_signal": "CI runs pytest tests/schemas/ on every PR; failing schema tests block merge",
      "urgency": "P1",
      "owner_hint": "DevOps"
    },
    {
      "id": "Q_074",
      "area": "CI/CD",
      "question": "Does CI pipeline fail on MyPy type errors for all agents/?",
      "why_it_matters": "Coverage shows LintTypeClean=No for all components; type safety critical for deterministic agents",
      "evidence_anchor": [".github/workflows/ci.yml", "pyproject.toml", "mypy.ini"],
      "acceptance_signal": "CI runs mypy src/agents/ --strict; any type error fails build",
      "urgency": "P1",
      "owner_hint": "DevOps"
    },
    {
      "id": "Q_075",
      "area": "Infra",
      "question": "Is GKE cluster configured with node auto-scaling based on CPU/memory pressure?",
      "why_it_matters": "MMM/MTA training jobs spike resource usage; fixed cluster size causes job failures or waste",
      "evidence_anchor": ["terraform/gke.tf", "k8s/cluster-autoscaler.yml"],
      "acceptance_signal": "GKE autoscaling enabled with min=2, max=10 nodes; HPA configured for agent deployments",
      "urgency": "P2",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_076",
      "area": "Infra",
      "question": "Are Kafka topics configured with replication factor ≥ 3 for durability?",
      "why_it_matters": "Event bus critical path; RF < 3 risks data loss on node failures",
      "evidence_anchor": ["terraform/kafka.tf", "k8s/kafka/topics.yml"],
      "acceptance_signal": "All topics have replication.factor=3 and min.insync.replicas=2",
      "urgency": "P1",
      "owner_hint": "Infra"
    },
    {
      "id": "Q_077",
      "area": "RBAC",
      "question": "Does API authentication use JWT with role-based claims for agent endpoints?",
      "why_it_matters": "No RBAC implementation visible; missing auth allows unauthorized budget/creative changes",
      "evidence_anchor": ["src/api/auth.py", "src/api/middleware.py", "tests/test_api_auth.py"],
      "acceptance_signal": "Endpoints check JWT roles; /decisions/* requires 'executor' role; test validates unauthorized 403",
      "urgency": "P1",
      "owner_hint": "Security"
    },
    {
      "id": "Q_078",
      "area": "RBAC",
      "question": "Is row-level security (RLS) enforced on dim_user table by team ownership?",
      "why_it_matters": "GDPR requires data minimization; analysts should only access users in their region/team",
      "evidence_anchor": ["db/schema/dim_user.sql", "db/policies/rls_policies.sql", "tests/test_rls.py"],
      "acceptance_signal": "PostgreSQL RLS policy filters dim_user by current_user team; test validates isolation",
      "urgency": "P1",
      "owner_hint": "Security"
    },
    {
      "id": "Q_079",
      "area": "Governance",
      "question": "Are all automated decisions (budget/creative) requiring approval above $50k threshold?",
      "why_it_matters": "Playbook orchestration needs human-in-loop; missing approval gates risk large losses",
      "evidence_anchor": ["src/agents/playbook/playbook_orchestrator.py", "config/approval_policy.yml", "tests/test_approval_gates.py"],
      "acceptance_signal": "Decision with total_budget > 50000 sets requires_approval=true; blocked until approved",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_080",
      "area": "Governance",
      "question": "Is there a kill-switch API endpoint to pause all active playbooks immediately?",
      "why_it_matters": "Crisis scenarios require instant shutdown; missing kill-switch prevents rapid response",
      "evidence_anchor": ["src/api/emergency.py", "tests/test_kill_switch.py"],
      "acceptance_signal": "POST /emergency/kill-switch pauses all playbooks; returns within 500ms; test validates",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_081",
      "area": "Data",
      "question": "Does Data Quality Agent check schema drift detection on ingestion tables daily?",
      "why_it_matters": "C07 ingestion complete but quality monitoring missing; schema changes break downstream pipelines",
      "evidence_anchor": ["src/agents/data_quality/data_quality_agent.py", "tests/test_schema_drift.py"],
      "acceptance_signal": "Daily job compares current schema to baseline; alerts on column add/drop/type change",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_082",
      "area": "Data",
      "question": "Are null rates tracked for critical columns (spend, revenue, user_key)?",
      "why_it_matters": "Data quality agent spec exists but null tracking not visible; high nulls corrupt aggregations",
      "evidence_anchor": ["src/agents/data_quality/data_quality_agent.py", "db/views/data_quality_metrics.sql", "tests/test_null_tracking.py"],
      "acceptance_signal": "View computes null_rate for each critical column; alert if > 1% nulls",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_083",
      "area": "Observability",
      "question": "Is distributed tracing (OpenTelemetry) enabled for cross-agent request flows?",
      "why_it_matters": "Complex agent workflows span multiple services; missing tracing makes debugging impossible",
      "evidence_anchor": ["src/observability/otel_config.py", "k8s/otel-collector.yml", "tests/test_tracing.py"],
      "acceptance_signal": "All agent API calls emit OTEL spans; trace_id propagates via headers; Jaeger UI shows flows",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_084",
      "area": "Observability",
      "question": "Are playbook execution failures logged with full stack traces to centralized logging?",
      "why_it_matters": "Playbook errors invisible without structured logs; debugging requires log aggregation",
      "evidence_anchor": ["src/agents/playbook/playbook_orchestrator.py", "src/observability/logging_config.py", "tests/test_error_logging.py"],
      "acceptance_signal": "Failures log to structured JSON with trace, playbook_id, step_id; sent to CloudWatch/Stackdriver",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_085",
      "area": "RAG",
      "question": "Does RAG retriever chunk documents with semantic boundaries (sentences/paragraphs)?",
      "why_it_matters": "LLM council requires RAG; naive chunking by char count breaks context and reduces retrieval quality",
      "evidence_anchor": ["src/agents/llm/rag_retriever.py", "tests/test_rag_chunking.py"],
      "acceptance_signal": "Chunker splits on sentence/paragraph boundaries using spaCy; test validates chunk coherence",
      "urgency": "P1",
      "owner_hint": "ML"
    },
    {
      "id": "Q_086",
      "area": "RAG",
      "question": "Is vector database (e.g., Pinecone/Weaviate) index updated incrementally on SSOT changes?",
      "why_it_matters": "RAG answers stale if index not refreshed; missing incremental updates require full reindex",
      "evidence_anchor": ["src/agents/llm/vector_db.py", "src/agents/llm/index_updater.py", "tests/test_incremental_index.py"],
      "acceptance_signal": "On SSOT doc save, index_updater upserts embeddings; test validates delta update",
      "urgency": "P1",
      "owner_hint": "ML"
    },
    {
      "id": "Q_087",
      "area": "Strategy",
      "question": "Does Audience Clustering Agent use silhouette score to validate optimal k?",
      "why_it_matters": "C12 is Red; arbitrary k choice produces poor segments; silhouette score optimizes cluster quality",
      "evidence_anchor": ["src/agents/audience/audience_clustering_agent.py", "tests/test_clustering_quality.py"],
      "acceptance_signal": "Agent sweeps k=2..10, selects k with highest silhouette score; test validates selection",
      "urgency": "P2",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_088",
      "area": "Strategy",
      "question": "Are lookalike audience expansions tested via holdout A/B before scaling?",
      "why_it_matters": "Queue item Q_009 on audience expansion; scaling untested lookalikes risks wasted spend",
      "evidence_anchor": ["src/agents/audience/audience_expansion_agent.py", "tests/test_lookalike_validation.py"],
      "acceptance_signal": "Expansion creates test cohort with 10% budget; only scales if CPA < control * 1.2",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_089",
      "area": "Planner",
      "question": "Does Budget Allocation optimizer use convex optimization (SLSQP) for global optimum?",
      "why_it_matters": "C08 spec shows scipy.minimize; non-convex methods may find local optima and misallocate budget",
      "evidence_anchor": ["src/agents/budget/budget_allocation_agent.py", "tests/test_budget_optimization.py"],
      "acceptance_signal": "Uses method='SLSQP' with convex ROI curves; test validates global optimum on synthetic data",
      "urgency": "P1",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_090",
      "area": "Planner",
      "question": "Are MMM ROI curves smoothed to prevent optimization instability?",
      "why_it_matters": "Noisy ROI curves cause optimizer to oscillate; smoothing (e.g., Savitzky-Golay) stabilizes allocations",
      "evidence_anchor": ["src/agents/mmm/mmm_agent.py", "tests/test_roi_smoothing.py"],
      "acceptance_signal": "ROI curve applies scipy.signal.savgol_filter before optimization; test validates smoothness",
      "urgency": "P2",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_091",
      "area": "Critic",
      "question": "Does Policy Agent reject creatives with banned medical/financial claims before activation?",
      "why_it_matters": "Compliance gap; activating prohibited claims risks regulatory fines and platform bans",
      "evidence_anchor": ["src/agents/compliance/policy_agent.py", "config/banned_claims.yml", "tests/test_claim_rejection.py"],
      "acceptance_signal": "Agent checks text against banned_claims regex list; activation blocked if match; logged",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_092",
      "area": "Critic",
      "question": "Are LLM-generated creative variants validated for toxicity before approval?",
      "why_it_matters": "LLM guardrails include toxicity check (Q_004) but may not apply to generated creative output",
      "evidence_anchor": ["src/agents/creative/creative_intelligence_agent.py", "src/agents/llm/llm_guardrails.py", "tests/test_creative_toxicity.py"],
      "acceptance_signal": "CreativeVariant calls toxicity_detector.score before returning; rejects if score > 0.8",
      "urgency": "P1",
      "owner_hint": "ML"
    },
    {
      "id": "Q_093",
      "area": "Rules",
      "question": "Does Pacing Agent implement daily budget caps with exponential smoothing for overspend prevention?",
      "why_it_matters": "C15 is Red; naive pacing causes budget exhaustion early in day; exponential smoothing balances spend",
      "evidence_anchor": ["src/agents/pacing/pacing_agent.py", "tests/test_pacing_smoothing.py"],
      "acceptance_signal": "Pacing uses EMA of hourly spend; throttles bids when projected daily > cap * 1.05",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_094",
      "area": "Rules",
      "question": "Are frequency capping rules enforced at user-level to prevent creative fatigue?",
      "why_it_matters": "Creative fatigue detection exists (C04) but per-user frequency caps may not be enforced in activation",
      "evidence_anchor": ["src/agents/activation/activation_agent.py", "db/schema/user_frequency.sql", "tests/test_frequency_capping.py"],
      "acceptance_signal": "Activation queries user_frequency table; skips impression if user_key seen > 5 times in 24h",
      "urgency": "P1",
      "owner_hint": "Execution"
    },
    {
      "id": "Q_095",
      "area": "Latency",
      "question": "Does Identity Resolution Agent use Redis cache for deterministic match lookups?",
      "why_it_matters": "C01 GDPR compliance done but latency may exceed <50ms without caching",
      "evidence_anchor": ["src/agents/identity/identity_resolution_agent.py", "tests/test_identity_cache.py"],
      "acceptance_signal": "Deterministic matches query Redis first; cache hit < 10ms; cache miss fetches DB and updates cache",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_096",
      "area": "Latency",
      "question": "Is probabilistic identity matching batched to amortize XGBoost inference cost?",
      "why_it_matters": "C01 spec shows XGBoost similarity model; per-request inference causes high latency",
      "evidence_anchor": ["src/agents/identity/identity_resolution_agent.py", "tests/test_identity_batching.py"],
      "acceptance_signal": "Probabilistic matcher batches ≥ 10 requests; inference runs every 100ms; test validates batching",
      "urgency": "P1",
      "owner_hint": "DataOps"
    },
    {
      "id": "Q_097",
      "area": "SimLab",
      "question": "Does MMM simulator support counterfactual budget scenarios for planning?",
      "why_it_matters": "Marketers need what-if analysis; missing simulator forces manual scenario testing",
      "evidence_anchor": ["src/agents/mmm/mmm_simulator.py", "tests/test_mmm_scenarios.py"],
      "acceptance_signal": "Simulator takes budget_scenario dict; returns projected revenue using MMM ROI curves; test validates",
      "urgency": "P2",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_098",
      "area": "SimLab",
      "question": "Are geo-experiment power calculations automated for incrementality test design?",
      "why_it_matters": "C14 is Red; manual power analysis error-prone; automated calculation ensures statistical validity",
      "evidence_anchor": ["src/agents/incrementality/incrementality_agent.py", "tests/test_power_analysis.py"],
      "acceptance_signal": "design_geo_experiment computes required sample size for 80% power, 5% alpha; test validates formula",
      "urgency": "P2",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_099",
      "area": "Backtest",
      "question": "Does MTA use time-decay attribution weights to prioritize recent touchpoints?",
      "why_it_matters": "C03 Markov attribution treats all touchpoints equally; time-decay better reflects user journey",
      "evidence_anchor": ["src/agents/mta/mta_agent.py", "tests/test_time_decay.py"],
      "acceptance_signal": "MTA applies exponential decay to touchpoint weights by position; test validates decay curve",
      "urgency": "P2",
      "owner_hint": "Analytics"
    },
    {
      "id": "Q_100",
      "area": "Other",
      "question": "Is dbt incremental model strategy configured for large tables (>10M rows)?",
      "why_it_matters": "fct_ad_metric_daily grows unbounded; full refresh causes excessive compute/cost",
      "evidence_anchor": ["dbt/models/core/fct_ad_metric_daily.sql", "dbt_project.yml", "tests/test_dbt_incremental.py"],
      "acceptance_signal": "Model uses materialized='incremental' with unique_key; only processes new partitions",
      "urgency": "P1",
      "owner_hint": "DataOps"
    }
  ]
}
